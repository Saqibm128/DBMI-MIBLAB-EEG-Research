{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.realpath(\"..\"))\n",
    "\n",
    "import util_funcs\n",
    "from importlib import reload\n",
    "reload(util_funcs)\n",
    "from copy import deepcopy as cp\n",
    "\n",
    "import data_reader as read\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "import tsfresh.feature_extraction.feature_calculators as feats\n",
    "import constants\n",
    "import clinical_text_analysis as cta\n",
    "reload(cta)\n",
    "import tsfresh\n",
    "import ensembleReader as er\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, roc_curve, r2_score\n",
    "from os import path\n",
    "\n",
    "reload(read)\n",
    "import wf_analysis.datasets as wfdata\n",
    "import wf_analysis.filters as filt\n",
    "reload(filt)\n",
    "from addict import Dict\n",
    "import time\n",
    "import pickle as pkl\n",
    "import tsfresh.feature_extraction.feature_calculators as tsf\n",
    "import pyedflib as edf\n",
    "import keras_models.dataGen as dg \n",
    "import keras_models.cnn_models as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to mess around with pulling the data\n",
    "Try using the seizure type, is seizure or not, and the patient identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pkl.load(open(\"/n/scratch2/ms994/train_multiple_labels_seizure_data_4.pkl\", \"rb\"))\n",
    "valid_data = pkl.load(open(\"/n/scratch2/ms994/valid_multiple_labels_seizure_data_4.pkl\", \"rb\"))\n",
    "test_data = pkl.load(open(\"/n/scratch2/ms994/test_multiple_labels_seizure_data_4.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_edss = train_data\n",
    "valid_edss = valid_data\n",
    "test_edss = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, 40, 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][1] # is seizure, patient number, seizure type (index of constants.SEIZURE_SUBTYPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Test Data Seizure Types\")\n",
    "num_types, bins, _ = plt.hist([test_data[i][1][2] for i in range(len(test_data))])\n",
    "plt.bar(height=num_types, x=constants.SEIZURE_SUBTYPES[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Train Data Seizure Types\")\n",
    "num_types, _, _ = plt.hist([train_data[i][1][2] for i in range(len(train_data))])\n",
    "plt.bar(height=num_types, x=constants.SEIZURE_SUBTYPES[:len(num_types)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Valid Seizure Types\")\n",
    "num_types, _, _ = plt.hist([valid_data[i][1][2] for i in range(len(valid_data))])\n",
    "plt.bar(height=num_types, x=constants.SEIZURE_SUBTYPES[:len(num_types)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 4, 6}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([valid_data[i][1][2] for i in range(len(valid_data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 6, 8, 10}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([test_data[i][1][2] for i in range(len(test_data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 8}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([train_data[i][1][2] for i in range(len(train_data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'atsz'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constants.SEIZURE_SUBTYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "patientInd = [datum[1][1] for datum in train_edss]\n",
    "seizureLabels = [datum[1][0] for datum in train_edss]\n",
    "seizureSubtypes = [datum[1][2] for datum in train_edss]\n",
    "validSeizureSubtypes = [datum[1][2] for datum in valid_edss]\n",
    "validPatientInd = [datum[1][1] for datum in valid_edss]\n",
    "validSeizureLabels = [datum[1][0] for datum in valid_edss]\n",
    "allPatients = list(set([datum[1][1] for datum in train_edss]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "edg = dg.RULDataGenMultipleLabels(train_edss, num_labels=3, precache=True, batch_size=64, labels=[seizureLabels, patientInd, seizureLabels], n_classes=(2, len(allPatients), len(constants.SEIZURE_SUBTYPES)),)\n",
    "valid_edg = dg.DataGenMultipleLabels(valid_edss, num_labels=3, precache=True, batch_size=64*4, labels=[validSeizureLabels, validPatientInd, validSeizureLabels], xy_tuple_form=True, n_classes=(2, len(allPatients), len(constants.SEIZURE_SUBTYPES)), shuffle=False)\n",
    "test_edg = dg.DataGenMultipleLabels(test_edss[:], num_labels=3, precache=True, n_classes=(2, len(allPatients), len(constants.SEIZURE_SUBTYPES)), batch_size=64*4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[-3.60817475e-01],\n",
       "          [-2.04936445e-01],\n",
       "          [-5.48891304e-01],\n",
       "          ...,\n",
       "          [-7.55603095e-01],\n",
       "          [-5.57363136e-01],\n",
       "          [-6.86134373e-01]],\n",
       " \n",
       "         [[-2.58557900e+00],\n",
       "          [-1.42694061e+00],\n",
       "          [-3.88846985e+00],\n",
       "          ...,\n",
       "          [-5.29217571e+00],\n",
       "          [-3.83386576e+00],\n",
       "          [-4.86835270e+00]],\n",
       " \n",
       "         [[-8.33339513e+00],\n",
       "          [-4.41622357e+00],\n",
       "          [-1.23720132e+01],\n",
       "          ...,\n",
       "          [-1.65825318e+01],\n",
       "          [-1.16706859e+01],\n",
       "          [-1.55176327e+01]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 2.75579375e+01],\n",
       "          [ 2.09551699e+00],\n",
       "          [ 4.58283894e+01],\n",
       "          ...,\n",
       "          [ 5.12419389e+01],\n",
       "          [ 1.56110453e+00],\n",
       "          [ 9.00921967e+00]],\n",
       " \n",
       "         [[ 3.01361566e+01],\n",
       "          [ 2.61404004e+00],\n",
       "          [ 5.02087604e+01],\n",
       "          ...,\n",
       "          [ 5.48896160e+01],\n",
       "          [ 5.55902375e+00],\n",
       "          [ 1.63115628e+01]],\n",
       " \n",
       "         [[ 3.40895440e+01],\n",
       "          [ 3.17655623e+00],\n",
       "          [ 5.75170373e+01],\n",
       "          ...,\n",
       "          [ 6.01466267e+01],\n",
       "          [ 1.11924699e+01],\n",
       "          [ 2.08837143e+01]]],\n",
       " \n",
       " \n",
       "        [[[-5.42113885e-01],\n",
       "          [-2.23574386e-01],\n",
       "          [-1.99853361e-01],\n",
       "          ...,\n",
       "          [-4.54007202e-01],\n",
       "          [-9.18261621e-01],\n",
       "          [-5.01449292e-01]],\n",
       " \n",
       "         [[-3.77695013e+00],\n",
       "          [-1.50742320e+00],\n",
       "          [-1.45766993e+00],\n",
       "          ...,\n",
       "          [-3.21164749e+00],\n",
       "          [-6.38950969e+00],\n",
       "          [-3.55514199e+00]],\n",
       " \n",
       "         [[-1.17710179e+01],\n",
       "          [-4.49755199e+00],\n",
       "          [-4.84050122e+00],\n",
       "          ...,\n",
       "          [-1.02412469e+01],\n",
       "          [-1.98581132e+01],\n",
       "          [-1.13165659e+01]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-5.00176784e-01],\n",
       "          [-1.74968317e+00],\n",
       "          [ 4.44452956e+00],\n",
       "          ...,\n",
       "          [ 7.97910608e+00],\n",
       "          [-4.57798512e+00],\n",
       "          [ 6.01878413e+00]],\n",
       " \n",
       "         [[-2.20912623e+00],\n",
       "          [-1.34311283e+00],\n",
       "          [ 2.02600002e+00],\n",
       "          ...,\n",
       "          [ 5.37740669e+00],\n",
       "          [-5.09676727e+00],\n",
       "          [ 4.35914407e+00]],\n",
       " \n",
       "         [[-3.85288167e+00],\n",
       "          [-1.45423754e+00],\n",
       "          [-9.56262804e-01],\n",
       "          ...,\n",
       "          [ 4.94544907e+00],\n",
       "          [-6.04851834e+00],\n",
       "          [ 3.19463525e+00]]],\n",
       " \n",
       " \n",
       "        [[[-4.31980570e-01],\n",
       "          [-7.20021547e-01],\n",
       "          [-2.26963096e-01],\n",
       "          ...,\n",
       "          [-7.89490268e-01],\n",
       "          [-1.79521045e-01],\n",
       "          [ 1.71211291e-01]],\n",
       " \n",
       "         [[-2.98560411e+00],\n",
       "          [-4.98541855e+00],\n",
       "          [-1.70381488e+00],\n",
       "          ...,\n",
       "          [-5.54140158e+00],\n",
       "          [-1.28238010e+00],\n",
       "          [ 1.15850925e+00]],\n",
       " \n",
       "         [[-9.21794927e+00],\n",
       "          [-1.54351671e+01],\n",
       "          [-5.91502187e+00],\n",
       "          ...,\n",
       "          [-1.74734027e+01],\n",
       "          [-4.10111443e+00],\n",
       "          [ 3.43828194e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-1.50290377e+01],\n",
       "          [-5.40692352e+00],\n",
       "          [-2.08152768e+01],\n",
       "          ...,\n",
       "          [-3.23671063e+01],\n",
       "          [-2.88718706e+00],\n",
       "          [-3.06959298e+00]],\n",
       " \n",
       "         [[-1.40908085e+01],\n",
       "          [-4.75084600e+00],\n",
       "          [-2.23138672e+01],\n",
       "          ...,\n",
       "          [-3.38236898e+01],\n",
       "          [-1.60867700e-03],\n",
       "          [-2.18367116e+00]],\n",
       " \n",
       "         [[-1.30372529e+01],\n",
       "          [-4.44484215e+00],\n",
       "          [-2.21557897e+01],\n",
       "          ...,\n",
       "          [-3.34588890e+01],\n",
       "          [ 2.89259325e+00],\n",
       "          [-1.80268264e+00]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[-5.00206101e-03],\n",
       "          [-4.56666811e-02],\n",
       "          [ 5.99884123e-01],\n",
       "          ...,\n",
       "          [ 3.28786695e-01],\n",
       "          [ 9.66594860e-02],\n",
       "          [-1.98158987e-01]],\n",
       " \n",
       "         [[-2.59439465e-03],\n",
       "          [-2.95565773e-01],\n",
       "          [ 4.14144178e+00],\n",
       "          ...,\n",
       "          [ 2.33401439e+00],\n",
       "          [ 6.87475056e-01],\n",
       "          [-1.46452423e+00]],\n",
       " \n",
       "         [[ 1.19194223e-01],\n",
       "          [-8.06446191e-01],\n",
       "          [ 1.27939364e+01],\n",
       "          ...,\n",
       "          [ 7.43758155e+00],\n",
       "          [ 2.19800903e+00],\n",
       "          [-4.97078509e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 7.17528451e+00],\n",
       "          [ 8.12888580e-01],\n",
       "          [ 2.81363715e+00],\n",
       "          ...,\n",
       "          [-2.59995025e+00],\n",
       "          [ 1.55818782e+00],\n",
       "          [ 6.07116309e-01]],\n",
       " \n",
       "         [[ 6.00143040e+00],\n",
       "          [-2.90852549e-01],\n",
       "          [ 2.82187962e+00],\n",
       "          ...,\n",
       "          [-3.77149154e+00],\n",
       "          [ 5.74582202e+00],\n",
       "          [ 1.70669547e+00]],\n",
       " \n",
       "         [[ 4.20263046e+00],\n",
       "          [-1.87025955e+00],\n",
       "          [ 2.16904027e+00],\n",
       "          ...,\n",
       "          [-5.31118546e+00],\n",
       "          [ 9.82943066e+00],\n",
       "          [ 3.98552816e+00]]],\n",
       " \n",
       " \n",
       "        [[[ 5.35498486e-01],\n",
       "          [-2.18491303e-01],\n",
       "          [ 3.90512772e-02],\n",
       "          ...,\n",
       "          [-2.03242071e-01],\n",
       "          [-2.84571315e-01],\n",
       "          [-1.28690275e-01]],\n",
       " \n",
       "         [[ 3.79532847e+00],\n",
       "          [-1.50087661e+00],\n",
       "          [ 3.57997417e-01],\n",
       "          ...,\n",
       "          [-1.37618670e+00],\n",
       "          [-1.89435512e+00],\n",
       "          [-8.78042821e-01]],\n",
       " \n",
       "         [[ 1.21266814e+01],\n",
       "          [-4.60498334e+00],\n",
       "          [ 1.51253527e+00],\n",
       "          ...,\n",
       "          [-4.09503589e+00],\n",
       "          [-5.50886200e+00],\n",
       "          [-2.66622637e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-2.03678805e+01],\n",
       "          [-7.56553277e+00],\n",
       "          [-3.21579135e+01],\n",
       "          ...,\n",
       "          [-2.84151480e+01],\n",
       "          [-1.84014527e+01],\n",
       "          [ 4.37267750e+00]],\n",
       " \n",
       "         [[-2.20367062e+01],\n",
       "          [-9.15500087e+00],\n",
       "          [-3.37111003e+01],\n",
       "          ...,\n",
       "          [-3.06718893e+01],\n",
       "          [-1.91552353e+01],\n",
       "          [ 3.08884167e-01]],\n",
       " \n",
       "         [[-2.36661382e+01],\n",
       "          [-1.02063360e+01],\n",
       "          [-3.46548216e+01],\n",
       "          ...,\n",
       "          [-3.27084610e+01],\n",
       "          [-1.98929366e+01],\n",
       "          [-4.19730328e+00]]],\n",
       " \n",
       " \n",
       "        [[[ 2.50846161e-01],\n",
       "          [ 1.20380511e-01],\n",
       "          [ 6.28688213e-01],\n",
       "          ...,\n",
       "          [ 4.33836926e-01],\n",
       "          [ 1.42407182e-01],\n",
       "          [ 2.08075402e+00]],\n",
       " \n",
       "         [[ 1.71403044e+00],\n",
       "          [ 7.71115516e-01],\n",
       "          [ 4.30956923e+00],\n",
       "          ...,\n",
       "          [ 2.93243431e+00],\n",
       "          [ 1.00732528e+00],\n",
       "          [ 1.45554817e+01]],\n",
       " \n",
       "         [[ 5.22499424e+00],\n",
       "          [ 2.12800672e+00],\n",
       "          [ 1.32127653e+01],\n",
       "          ...,\n",
       "          [ 8.74767141e+00],\n",
       "          [ 3.30672418e+00],\n",
       "          [ 4.56303671e+01]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-1.39847816e+01],\n",
       "          [ 2.24363367e+00],\n",
       "          [-2.76503300e+01],\n",
       "          ...,\n",
       "          [-2.38696195e+01],\n",
       "          [-8.11328108e+00],\n",
       "          [-2.89078630e+01]],\n",
       " \n",
       "         [[-1.24480145e+01],\n",
       "          [ 2.33338259e+00],\n",
       "          [-2.41688448e+01],\n",
       "          ...,\n",
       "          [-2.11372299e+01],\n",
       "          [-6.47368004e+00],\n",
       "          [-2.70819367e+01]],\n",
       " \n",
       "         [[-1.14155644e+01],\n",
       "          [ 2.28608797e+00],\n",
       "          [-2.17239185e+01],\n",
       "          ...,\n",
       "          [-1.93835182e+01],\n",
       "          [-5.55455252e+00],\n",
       "          [-2.52240241e+01]]]]), [array([[1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.]], dtype=float32), array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_edg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-1fa293707669>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_edg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataGenMultipleLabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_edss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/dbmi_eeg_clustering/keras_models/dataGen.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, mask_value, labels, batch_size, dim, n_channels, n_classes, class_type, shuffle, max_length, time_first, precache, xy_tuple_form, num_labels, shuffle_channels, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m                      n_classes, class_type, shuffle, max_length, time_first, precache=precache, xy_tuple_form=xy_tuple_form, **kwargs)\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;31m# assert num_labels >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mnum_labels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mxy_tuple_form\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "test_edg = dg.DataGenMultipleLabels(test_edss[:], n_classes=2, precache=True, batch_size=64*4, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 3, 2)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_edg[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "edg.on_epoch_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_edg[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_edg[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_edg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_patients = max([datum[1][1] for datum in train_edss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           (None, 1000, 21, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 1000, 21, 1)  4           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 1000, 21, 32) 544         batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_90 (MaxPooling2D) (None, 500, 21, 32)  0           conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 500, 21, 32)  0           max_pooling2d_90[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 500, 21, 32)  128         dropout_78[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 500, 21, 32)  16416       batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_91 (MaxPooling2D) (None, 250, 21, 32)  0           conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 250, 21, 32)  0           max_pooling2d_91[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 250, 21, 32)  128         dropout_79[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 250, 21, 32)  16416       batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_92 (MaxPooling2D) (None, 125, 21, 32)  0           conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 125, 21, 32)  0           max_pooling2d_92[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 125, 21, 32)  128         dropout_80[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 125, 21, 32)  16416       batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_93 (MaxPooling2D) (None, 62, 21, 32)   0           conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)            (None, 62, 21, 32)   0           max_pooling2d_93[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 62, 21, 32)   128         dropout_81[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 62, 21, 32)   16416       batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_94 (MaxPooling2D) (None, 31, 21, 32)   0           conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)            (None, 31, 21, 32)   0           max_pooling2d_94[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 31, 21, 32)   128         dropout_82[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 31, 21, 32)   16416       batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_95 (MaxPooling2D) (None, 15, 21, 32)   0           conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)            (None, 15, 21, 32)   0           max_pooling2d_95[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 15, 21, 64)   32832       dropout_83[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_96 (MaxPooling2D) (None, 7, 21, 64)    0           conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 7, 21, 64)    256         max_pooling2d_96[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 7, 21, 64)    65600       batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_97 (MaxPooling2D) (None, 3, 21, 64)    0           conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 3, 21, 64)    256         max_pooling2d_97[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 3, 21, 64)    65600       batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_98 (MaxPooling2D) (None, 1, 21, 64)    0           conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 1, 21, 64)    256         max_pooling2d_98[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 1344)         0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 100)          134500      flatten_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)            (None, 100)          0           dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 100)          10100       dropout_84[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)            (None, 100)          0           dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "seizure (Dense)                 (None, 2)            202         dropout_85[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "patient (Dense)                 (None, 246)          24846       dropout_85[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "seizure_subtype (Dense)         (None, 11)           1111        dropout_85[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 418,827\n",
      "Trainable params: 418,121\n",
      "Non-trainable params: 706\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras.layers import Dense, TimeDistributed, Input, Reshape, Dropout, LSTM, Flatten\n",
    "from keras.models import Model, load_model\n",
    "input_time_size = 4 * constants.COMMON_FREQ\n",
    "x = Input((input_time_size, 21, 1)) #time, ecg channel, cnn channel\n",
    "y = x\n",
    "_, y = cm.conv2d_gridsearch_pre_layers(input_shape=(input_time_size,21,1),\n",
    "                                            x=y,\n",
    "                                            conv_spatial_filter=(4,4),\n",
    "                                            conv_temporal_filter=(4,4),\n",
    "                                            max_pool_size=(2,1),\n",
    "                                            max_pool_stride=None,\n",
    "                                            dropout=0,\n",
    "                                            num_conv_spatial_layers=3,\n",
    "                                            num_conv_temporal_layers=6,\n",
    "                                            num_spatial_filter=8,\n",
    "                                            num_temporal_filter=4,\n",
    "                                            use_batch_normalization=True,\n",
    "                                            time_convolutions_first=True,\n",
    "                                            max_pool_size_time=(2,1),\n",
    "                                            \n",
    "                                      )\n",
    "\n",
    "y = Flatten()(y)\n",
    "for i in range(2):\n",
    "    y = Dense(100, activation='relu')(y)\n",
    "    y = Dropout(0.25)(y)\n",
    "y_seizure = Dense(2, activation=\"softmax\", name=\"seizure\")(y)\n",
    "y_seizure_subtype = Dense(len(constants.SEIZURE_SUBTYPES), activation=\"softmax\", name=\"seizure_subtype\")(y)\n",
    "y_patient = Dense(len(allPatients), activation=\"softmax\", name=\"patient\")(y)\n",
    "\n",
    "seizure_model = Model(inputs=x, outputs=[y_seizure])\n",
    "seizure_patient_model = Model(inputs=[x], outputs=[y_seizure, y_patient,  y_seizure_subtype,])\n",
    "\n",
    "patient_model = Model(inputs=[x], outputs=[y_patient])\n",
    "print(seizure_patient_model.summary())\n",
    "    \n",
    "lr=0.0001\n",
    "seizure_weight=1\n",
    "patient_weight=-1\n",
    "seizure_model.compile(optimizers.Adam(lr=lr), loss=[\"categorical_crossentropy\"], metrics=[\"binary_accuracy\"])\n",
    "seizure_patient_model.compile(optimizers.Adam(lr=lr), loss=[\"categorical_crossentropy\", \"categorical_crossentropy\", \"categorical_crossentropy\"], loss_weights=[seizure_weight,patient_weight, seizure_weight], metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "patient_model.compile(optimizers.Adam(lr=lr), loss=[\"categorical_crossentropy\"], metrics=[\"categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss, accuracy_score, roc_auc_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 batch: 0/585, seizure acc: 0.546875, patient acc: 0.0, loss: -2.052402973175049, seizure_subtype accs: 0.109375\n",
      "epoch: 0 batch: 100/585, seizure acc: 0.6115408539772034, patient acc: 0.004486386198550463, loss: -4.131728172302246, seizure_subtype accs: 0.41460394859313965\n",
      "epoch: 0 batch: 200/585, seizure acc: 0.6230565905570984, patient acc: 0.0070740049704909325, loss: -7.521538257598877, seizure_subtype accs: 0.4458177983760834\n",
      "epoch: 0 batch: 300/585, seizure acc: 0.6279069781303406, patient acc: 0.007267442066222429, loss: -7.448182106018066, seizure_subtype accs: 0.4486088156700134\n",
      "epoch: 0 batch: 400/585, seizure acc: 0.6350919604301453, patient acc: 0.00798784289509058, loss: -7.98509407043457, seizure_subtype accs: 0.46317797899246216\n",
      "epoch: 0 batch: 500/585, seizure acc: 0.646332323551178, patient acc: 0.009356287308037281, loss: -6.446347236633301, seizure_subtype accs: 0.47813746333122253\n",
      "debug: valid_labels.shape (10304,), valid_predictions.shape (10304,)\n",
      "We predicted 2737.0 seizures in the validation split, there were actually 5152.0\n",
      "We predicted 0.265625 seizure/total in the validation split, there were actually 0.5\n",
      "end epoch: 0, f1: 0.5714285714285714, auc: 0.7202753441802253, acc: 0.671875, loss: 0.8115363360120682\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.91      0.73      5152\n",
      "         1.0       0.82      0.44      0.57      5152\n",
      "\n",
      "    accuracy                           0.67     10304\n",
      "   macro avg       0.72      0.67      0.65     10304\n",
      "weighted avg       0.72      0.67      0.65     10304\n",
      "\n",
      "improved val score to 0.8115363360120682\n",
      "epoch: 1 batch: 0/585, seizure acc: 0.734375, patient acc: 0.015625, loss: -9.109306335449219, seizure_subtype accs: 0.515625\n",
      "epoch: 1 batch: 100/585, seizure acc: 0.7113242745399475, patient acc: 0.010674504563212395, loss: -10.690791130065918, seizure_subtype accs: 0.5951423048973083\n",
      "epoch: 1 batch: 200/585, seizure acc: 0.7242692708969116, patient acc: 0.010338930413126945, loss: -9.014683723449707, seizure_subtype accs: 0.6072761416435242\n",
      "epoch: 1 batch: 300/585, seizure acc: 0.7290282249450684, patient acc: 0.009759136475622654, loss: -10.528380393981934, seizure_subtype accs: 0.6220411062240601\n",
      "epoch: 1 batch: 400/585, seizure acc: 0.7353101372718811, patient acc: 0.01009195763617754, loss: -9.65899658203125, seizure_subtype accs: 0.6335333585739136\n",
      "epoch: 1 batch: 500/585, seizure acc: 0.7416105270385742, patient acc: 0.01022954098880291, loss: -10.93148422241211, seizure_subtype accs: 0.6434942483901978\n",
      "debug: valid_labels.shape (10304,), valid_predictions.shape (10304,)\n",
      "We predicted 4508.0 seizures in the validation split, there were actually 6279.0\n",
      "We predicted 0.4375 seizure/total in the validation split, there were actually 0.609375\n",
      "end epoch: 1, f1: 0.7761194029850746, auc: 0.7837301587301586, acc: 0.765625, loss: 0.8429566278937273\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.92      0.75      4025\n",
      "         1.0       0.93      0.67      0.78      6279\n",
      "\n",
      "    accuracy                           0.77     10304\n",
      "   macro avg       0.78      0.79      0.77     10304\n",
      "weighted avg       0.82      0.77      0.77     10304\n",
      "\n",
      "epoch: 2 batch: 0/585, seizure acc: 0.703125, patient acc: 0.0, loss: -9.646236419677734, seizure_subtype accs: 0.640625\n",
      "epoch: 2 batch: 100/585, seizure acc: 0.765625, patient acc: 0.009282178245484829, loss: -11.03300666809082, seizure_subtype accs: 0.6987932920455933\n",
      "epoch: 2 batch: 200/585, seizure acc: 0.7755752205848694, patient acc: 0.009406094439327717, loss: -10.908501625061035, seizure_subtype accs: 0.705534815788269\n",
      "epoch: 2 batch: 300/585, seizure acc: 0.7766299843788147, patient acc: 0.010122508741915226, loss: -11.461580276489258, seizure_subtype accs: 0.7077969312667847\n",
      "epoch: 2 batch: 400/585, seizure acc: 0.7794576287269592, patient acc: 0.010208852589130402, loss: -12.771475791931152, seizure_subtype accs: 0.7111128568649292\n",
      "epoch: 2 batch: 500/585, seizure acc: 0.7843687534332275, patient acc: 0.010479042306542397, loss: -11.696880340576172, seizure_subtype accs: 0.7155688405036926\n",
      "debug: valid_labels.shape (10304,), valid_predictions.shape (10304,)\n",
      "We predicted 4508.0 seizures in the validation split, there were actually 4669.0\n",
      "We predicted 0.4375 seizure/total in the validation split, there were actually 0.453125\n",
      "end epoch: 2, f1: 0.8421052631578947, auc: 0.8591269841269842, acc: 0.859375, loss: 0.436745789127599\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.89      0.87      5635\n",
      "         1.0       0.86      0.83      0.84      4669\n",
      "\n",
      "    accuracy                           0.86     10304\n",
      "   macro avg       0.86      0.86      0.86     10304\n",
      "weighted avg       0.86      0.86      0.86     10304\n",
      "\n",
      "improved val score to 0.436745789127599\n",
      "epoch: 3 batch: 0/585, seizure acc: 0.84375, patient acc: 0.0, loss: -11.585746765136719, seizure_subtype accs: 0.703125\n",
      "epoch: 3 batch: 100/585, seizure acc: 0.7995049357414246, patient acc: 0.01160272303968668, loss: -11.687994003295898, seizure_subtype accs: 0.7349938154220581\n",
      "epoch: 3 batch: 200/585, seizure acc: 0.8041045069694519, patient acc: 0.011271766386926174, loss: -11.976126670837402, seizure_subtype accs: 0.7400497794151306\n",
      "epoch: 3 batch: 300/585, seizure acc: 0.8047653436660767, patient acc: 0.010849252343177795, loss: -12.37341022491455, seizure_subtype accs: 0.7381125688552856\n",
      "epoch: 3 batch: 400/585, seizure acc: 0.8081748485565186, patient acc: 0.0104426434263587, loss: -11.879690170288086, seizure_subtype accs: 0.7385442852973938\n",
      "epoch: 3 batch: 500/585, seizure acc: 0.8114396333694458, patient acc: 0.010510229505598545, loss: -11.206676483154297, seizure_subtype accs: 0.7420159578323364\n",
      "debug: valid_labels.shape (10304,), valid_predictions.shape (10304,)\n",
      "We predicted 4991.0 seizures in the validation split, there were actually 5635.0\n",
      "We predicted 0.484375 seizure/total in the validation split, there were actually 0.546875\n",
      "end epoch: 3, f1: 0.787878787878788, auc: 0.7829912023460411, acc: 0.78125, loss: 0.5198331670835614\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.83      0.77      4669\n",
      "         1.0       0.84      0.74      0.79      5635\n",
      "\n",
      "    accuracy                           0.78     10304\n",
      "   macro avg       0.78      0.79      0.78     10304\n",
      "weighted avg       0.79      0.78      0.78     10304\n",
      "\n",
      "epoch: 4 batch: 0/585, seizure acc: 0.90625, patient acc: 0.03125, loss: -12.134469032287598, seizure_subtype accs: 0.734375\n",
      "epoch: 4 batch: 100/585, seizure acc: 0.8168317079544067, patient acc: 0.016398515552282333, loss: -12.14255428314209, seizure_subtype accs: 0.7611386179924011\n",
      "epoch: 4 batch: 200/585, seizure acc: 0.8189521431922913, patient acc: 0.02067786082625389, loss: -11.661477088928223, seizure_subtype accs: 0.7603389024734497\n",
      "epoch: 4 batch: 300/585, seizure acc: 0.8212209343910217, patient acc: 0.02393064834177494, loss: -11.398846626281738, seizure_subtype accs: 0.761731743812561\n",
      "epoch: 4 batch: 400/585, seizure acc: 0.8202930092811584, patient acc: 0.026574188843369484, loss: -10.596423149108887, seizure_subtype accs: 0.7595074772834778\n",
      "epoch: 4 batch: 500/585, seizure acc: 0.8196107745170593, patient acc: 0.02928517945110798, loss: -11.002546310424805, seizure_subtype accs: 0.7587325572967529\n",
      "debug: valid_labels.shape (10304,), valid_predictions.shape (10304,)\n",
      "We predicted 2898.0 seizures in the validation split, there were actually 5313.0\n",
      "We predicted 0.28125 seizure/total in the validation split, there were actually 0.515625\n",
      "end epoch: 4, f1: 0.6274509803921569, auc: 0.7596618357487922, acc: 0.703125, loss: 0.5681005149672274\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.94      0.75      4991\n",
      "         1.0       0.89      0.48      0.63      5313\n",
      "\n",
      "    accuracy                           0.70     10304\n",
      "   macro avg       0.76      0.71      0.69     10304\n",
      "weighted avg       0.76      0.70      0.69     10304\n",
      "\n",
      "epoch: 5 batch: 0/585, seizure acc: 0.875, patient acc: 0.046875, loss: -11.437657356262207, seizure_subtype accs: 0.765625\n",
      "epoch: 5 batch: 100/585, seizure acc: 0.8259591460227966, patient acc: 0.05198019742965698, loss: -11.70319652557373, seizure_subtype accs: 0.7696473002433777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 batch: 200/585, seizure acc: 0.8300684094429016, patient acc: 0.054415423423051834, loss: -12.592249870300293, seizure_subtype accs: 0.7681125402450562\n",
      "epoch: 5 batch: 300/585, seizure acc: 0.8289555907249451, patient acc: 0.05601121112704277, loss: -11.28227710723877, seizure_subtype accs: 0.7683762311935425\n",
      "epoch: 5 batch: 400/585, seizure acc: 0.8310084342956543, patient acc: 0.059265896677970886, loss: -10.393728256225586, seizure_subtype accs: 0.7681577205657959\n",
      "epoch: 5 batch: 500/585, seizure acc: 0.8319610953330994, patient acc: 0.06200099736452103, loss: -9.42205810546875, seizure_subtype accs: 0.7705214619636536\n",
      "debug: valid_labels.shape (10304,), valid_predictions.shape (10304,)\n",
      "We predicted 1932.0 seizures in the validation split, there were actually 4991.0\n",
      "We predicted 0.1875 seizure/total in the validation split, there were actually 0.484375\n",
      "end epoch: 5, f1: 0.5581395348837209, auc: 0.8173076923076923, acc: 0.703125, loss: 0.5985865495240432\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      1.00      0.78      5313\n",
      "         1.0       1.00      0.39      0.56      4991\n",
      "\n",
      "    accuracy                           0.70     10304\n",
      "   macro avg       0.82      0.69      0.67     10304\n",
      "weighted avg       0.81      0.70      0.67     10304\n",
      "\n",
      "epoch: 6 batch: 0/585, seizure acc: 0.765625, patient acc: 0.078125, loss: -9.479472160339355, seizure_subtype accs: 0.640625\n",
      "epoch: 6 batch: 100/585, seizure acc: 0.8321473002433777, patient acc: 0.06157178059220314, loss: -10.542762756347656, seizure_subtype accs: 0.7750619053840637\n",
      "epoch: 6 batch: 200/585, seizure acc: 0.8329446315765381, patient acc: 0.06203358247876167, loss: -10.66009521484375, seizure_subtype accs: 0.7731654047966003\n",
      "epoch: 6 batch: 300/585, seizure acc: 0.8357039093971252, patient acc: 0.06691237539052963, loss: -10.027941703796387, seizure_subtype accs: 0.7772529125213623\n",
      "epoch: 6 batch: 400/585, seizure acc: 0.8354114890098572, patient acc: 0.0730205699801445, loss: -10.041451454162598, seizure_subtype accs: 0.7788731455802917\n",
      "epoch: 6 batch: 500/585, seizure acc: 0.8367951512336731, patient acc: 0.07712699472904205, loss: -8.714763641357422, seizure_subtype accs: 0.7804079055786133\n",
      "debug: valid_labels.shape (10304,), valid_predictions.shape (10304,)\n",
      "We predicted 966.0 seizures in the validation split, there were actually 4347.0\n",
      "We predicted 0.09375 seizure/total in the validation split, there were actually 0.421875\n",
      "end epoch: 6, f1: 0.3636363636363636, auc: 0.8189655172413793, acc: 0.671875, loss: 0.7114605699753156\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      1.00      0.78      5957\n",
      "         1.0       1.00      0.22      0.36      4347\n",
      "\n",
      "    accuracy                           0.67     10304\n",
      "   macro avg       0.82      0.61      0.57     10304\n",
      "weighted avg       0.79      0.67      0.60     10304\n",
      "\n",
      "epoch: 7 batch: 0/585, seizure acc: 0.859375, patient acc: 0.09375, loss: -11.515604019165039, seizure_subtype accs: 0.828125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-011285dc147d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;31m#set weights that don't ruin seizure prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseizure_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                 \u001b[0mseizure_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moldNonPatientWeights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch: {} batch: {}/{}, seizure acc: {}, patient acc: {}, loss: {}, seizure_subtype accs: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseizure_accs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient_accs_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubtype_epochs_accs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   1057\u001b[0m                                  'provided weight shape ' + str(w.shape))\n\u001b[1;32m   1058\u001b[0m             \u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m         \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2468\u001b[0m             \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2469\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2470\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_seizure_accs = []\n",
    "valid_seizure_accs = []\n",
    "train_patient_accs = []\n",
    "training_seizure_loss = []\n",
    "valid_seizure_loss = []\n",
    "subtype_accs = []\n",
    "\n",
    "oldPatientWeights = patient_model.layers[-1].get_weights()\n",
    "oldNonPatientWeights = [layer.get_weights() for layer in seizure_model.layers[:-1]]\n",
    "best_model_loss = 100\n",
    "patience=20\n",
    "patience_left=patience\n",
    "steps_per_epoch=None\n",
    "model_name = \"test_model\"\n",
    "for i in range(100):\n",
    "        if patience_left == 0:\n",
    "            continue\n",
    "    #     edg.start_background()\n",
    "\n",
    "        valid_labels_full = []\n",
    "        valid_labels = []\n",
    "        valid_predictions_full = []\n",
    "        valid_predictions = []\n",
    "        \n",
    "\n",
    "        train_seizure_loss_epoch = []\n",
    "\n",
    "        seizure_accs = []\n",
    "        subtype_epochs_accs = []\n",
    "        patient_accs_epoch = []\n",
    "        # for j in range(len(edg)):\n",
    "        if steps_per_epoch is None:\n",
    "            steps_per_epoch = len(edg)\n",
    "        for j in range(steps_per_epoch):\n",
    "\n",
    "            train_batch = edg[j]\n",
    "            data_x = train_batch[0]\n",
    "            data_x = data_x.astype(np.float32)\n",
    "            data_x = np.nan_to_num(data_x)\n",
    "            loss, seizure_loss, patient_loss, subtype_loss, seizure_acc, patient_acc, subtype_acc = seizure_patient_model.train_on_batch(data_x, train_batch[1])\n",
    "            seizure_accs.append(seizure_acc)\n",
    "            #old patient weights are trying to predict for patient, try to do the prediction!\n",
    "            patient_model.layers[-1].set_weights(oldPatientWeights)\n",
    "            #keep the other nonpatient weights which try not to predict for patient!\n",
    "            oldNonPatientWeights = [layer.get_weights() for layer in seizure_model.layers[:-1]]\n",
    "            patient_loss, patient_acc = patient_model.train_on_batch(train_batch[0], train_batch[1][1])\n",
    "            patient_accs_epoch.append(patient_acc)\n",
    "\n",
    "            train_seizure_loss_epoch.append(seizure_loss)\n",
    "            subtype_epochs_accs.append(subtype_acc)\n",
    "\n",
    "            #get weights that try to predict for patient\n",
    "            oldPatientWeights = patient_model.layers[-1].get_weights()\n",
    "\n",
    "            #set weights that don't ruin seizure prediction\n",
    "            for layer_num, layer in enumerate(seizure_model.layers[:-1]):\n",
    "                seizure_model.layers[layer_num].set_weights(oldNonPatientWeights[layer_num])\n",
    "            if (j % 100) == 0:\n",
    "                print(\"epoch: {} batch: {}/{}, seizure acc: {}, patient acc: {}, loss: {}, seizure_subtype accs: {}\".format(i, j, len(edg), np.mean(seizure_accs), np.mean(patient_accs_epoch), loss, np.mean(subtype_epochs_accs)))\n",
    "    #     valid_edg.start_background()\n",
    "\n",
    "        for j in range(len(valid_edg)):\n",
    "            valid_batch = valid_edg[i]\n",
    "            data_x = valid_batch[0]\n",
    "            data_x = data_x.astype(np.float32)\n",
    "            data_x = np.nan_to_num(data_x) #ssome weird issue with incorrect data conversion\n",
    "            val_batch_predictions = seizure_model.predict_on_batch(data_x)\n",
    "            valid_labels.append(valid_batch[1][0].argmax(1))\n",
    "            valid_labels_full.append(valid_batch[1][0])\n",
    "            valid_predictions.append(val_batch_predictions.argmax(1))\n",
    "            valid_predictions_full.append(val_batch_predictions)\n",
    "\n",
    "\n",
    "        valid_labels = np.nan_to_num(np.hstack(valid_labels).astype(np.float32))\n",
    "        valid_predictions = np.nan_to_num(np.hstack(valid_predictions).astype(np.float32))\n",
    "\n",
    "        print(\"debug: valid_labels.shape {}, valid_predictions.shape {}\".format(valid_labels.shape, valid_predictions.shape))\n",
    "        print(\"We predicted {} seizures in the validation split, there were actually {}\".format(valid_predictions.sum(), valid_labels.sum()))\n",
    "        print(\"We predicted {} seizure/total in the validation split, there were actually {}\".format(valid_predictions.sum()/len(valid_predictions), valid_labels.sum()/len(valid_labels)))\n",
    "\n",
    "\n",
    "\n",
    "        valid_labels_full = np.nan_to_num(np.vstack(valid_labels_full).astype(np.float32))\n",
    "        valid_predictions_full = np.nan_to_num(np.vstack(valid_predictions_full).astype(np.float32))\n",
    "\n",
    "\n",
    "        try:\n",
    "            auc = roc_auc_score(valid_predictions, valid_labels)\n",
    "        except Exception:\n",
    "            auc = \"undefined\"\n",
    "        valid_acc =  accuracy_score(valid_predictions, valid_labels)\n",
    "        valid_seizure_accs.append(valid_acc)\n",
    "        train_patient_accs.append(np.mean(patient_accs_epoch))\n",
    "        valid_loss = log_loss(valid_labels_full, valid_predictions_full)\n",
    "        training_seizure_loss.append(np.mean(train_seizure_loss_epoch))\n",
    "        valid_seizure_loss.append(valid_loss)\n",
    "        subtype_accs.append(np.mean(subtype_epochs_accs))\n",
    "        print(\"end epoch: {}, f1: {}, auc: {}, acc: {}, loss: {}\\n\".format(i, f1_score(valid_predictions, valid_labels), auc, valid_acc, valid_loss))\n",
    "        print(classification_report(valid_labels, valid_predictions))\n",
    "        if (valid_loss < best_model_loss):\n",
    "            patience_left = patience\n",
    "            best_model_loss = valid_loss\n",
    "            try:\n",
    "                seizure_model.save(model_name)\n",
    "                print(\"improved val score to {}\".format(best_model_loss))\n",
    "            except Exception as e:\n",
    "                print(\"{}\\n\".format(e))\n",
    "                print(\"failed saving\\n\")\n",
    "        else:\n",
    "            patience_left -= 1\n",
    "            if patience_left == 0:\n",
    "                print(\"Early Stopping!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        training_seizure_accs.append(np.mean(seizure_accs))\n",
    "\n",
    "        edg.on_epoch_end()\n",
    "        valid_edg.on_epoch_end()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(valid_predictions, valid_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
