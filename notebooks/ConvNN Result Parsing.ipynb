{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import incense\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os\n",
    "sys.path.append(os.path.realpath(\"..\"))\n",
    "import util_funcs\n",
    "from copy import deepcopy\n",
    "from addict import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = util_funcs.get_sacred_runs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "successful_run_params = {\"status\":\"COMPLETED\", \"experiment.name\":\"gender_predict_conv_gridsearch\", \"num_files\":None, 'result.history': {'$exists':True}, '$or': [{'config.use_random_ensemble': False}, {'config.use_random_ensemble': {\"$exists\": False}}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: count is deprecated. Use Collection.count_documents instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = runs.find(successful_run_params).count()\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "allResults = Dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestValScore = 10000\n",
    "bestResult = None\n",
    "bestCheatScore =  0\n",
    "bestCheatResult = None\n",
    "index = -1\n",
    "cheatIndex = -1\n",
    "for i in range(total):\n",
    "    result = Dict(runs.find(successful_run_params)[i])\n",
    "    allResults[i].config = result.config\n",
    "    allResults[i].bestValScore = min(result.result.history.val_loss)\n",
    "    allResults[i].history = result.result.history\n",
    "    if (len(result.result.history[\"val_loss\"]) != 0 and min(result.result.history[\"val_loss\"]) < bestValScore):\n",
    "        bestValScore = min(result.result.history[\"val_loss\"])\n",
    "        bestResult = allResults[i]\n",
    "        index=i\n",
    "    if (result.result.test_scores.auc > bestCheatScore):\n",
    "        bestCheatScore = result.result.test_scores.auc\n",
    "        bestCheatResult = allResults[i]\n",
    "        cheatIndex = i\n",
    "    allResults[i].testScore = result.result.test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6007981523871422,\n",
       " 114,\n",
       " {'config': {'batch_size': 64,\n",
       "   'conv_spatial_filter': [3, 3],\n",
       "   'conv_temporal_filter': [2, 3],\n",
       "   'dropout': 0.25,\n",
       "   'lr': 0.0001,\n",
       "   'max_length': 500,\n",
       "   'max_pool_size': [2, 2],\n",
       "   'max_pool_stride': [1, 2],\n",
       "   'model_name': 'A1A6D77C361B8D6F3FCBB196131A8AF0.h5',\n",
       "   'n_process': 6,\n",
       "   'num_conv_spatial_layers': 7,\n",
       "   'num_conv_temporal_layers': 7,\n",
       "   'num_epochs': 500,\n",
       "   'num_files': None,\n",
       "   'num_spatial_filter': 300,\n",
       "   'num_temporal_filter': 300,\n",
       "   'patience': 20,\n",
       "   'precached_pkl': 'train_data.pkl',\n",
       "   'precached_test_pkl': 'test_data.pkl',\n",
       "   'ref': '01_tcp_ar',\n",
       "   'seed': 169492458,\n",
       "   'test_split': 'dev_test',\n",
       "   'train_split': 'train',\n",
       "   'use_cached_pkl': True,\n",
       "   'use_early_stopping': True,\n",
       "   'use_vp': False,\n",
       "   'validation_size': 0.2},\n",
       "  'bestValScore': 0.6007981523871422,\n",
       "  'testScore': {'acc': 0.5536649214659686,\n",
       "   'auc': 0.5895302988378528,\n",
       "   'f1': 0.624862486248625},\n",
       "  'history': {'binary_accuracy': [0.52001953125,\n",
       "    0.5078125,\n",
       "    0.49267578125,\n",
       "    0.525390625,\n",
       "    0.52685546875,\n",
       "    0.52685546875,\n",
       "    0.5234375,\n",
       "    0.5263671875,\n",
       "    0.52587890625,\n",
       "    0.53564453125,\n",
       "    0.5302734375,\n",
       "    0.5302734375,\n",
       "    0.537109375,\n",
       "    0.537109375,\n",
       "    0.5458984375,\n",
       "    0.54052734375,\n",
       "    0.54736328125,\n",
       "    0.5478515625,\n",
       "    0.54736328125,\n",
       "    0.5517578125,\n",
       "    0.5458984375,\n",
       "    0.5791015625,\n",
       "    0.57080078125,\n",
       "    0.56298828125,\n",
       "    0.54931640625,\n",
       "    0.55126953125,\n",
       "    0.54052734375,\n",
       "    0.56787109375,\n",
       "    0.583984375,\n",
       "    0.5830078125,\n",
       "    0.58984375,\n",
       "    0.59765625,\n",
       "    0.57080078125,\n",
       "    0.59130859375,\n",
       "    0.6064453125,\n",
       "    0.5927734375,\n",
       "    0.599609375,\n",
       "    0.58984375,\n",
       "    0.62109375,\n",
       "    0.62158203125,\n",
       "    0.62109375,\n",
       "    0.61083984375,\n",
       "    0.62890625,\n",
       "    0.623046875,\n",
       "    0.64599609375,\n",
       "    0.640625,\n",
       "    0.6494140625,\n",
       "    0.64794921875,\n",
       "    0.66015625,\n",
       "    0.6611328125,\n",
       "    0.66455078125,\n",
       "    0.67236328125,\n",
       "    0.68701171875,\n",
       "    0.68701171875,\n",
       "    0.7060546875,\n",
       "    0.69482421875,\n",
       "    0.7021484375,\n",
       "    0.7041015625,\n",
       "    0.7119140625,\n",
       "    0.701171875,\n",
       "    0.712890625,\n",
       "    0.7412109375,\n",
       "    0.73046875,\n",
       "    0.7587890625,\n",
       "    0.7373046875,\n",
       "    0.765625,\n",
       "    0.759765625,\n",
       "    0.76708984375,\n",
       "    0.77001953125,\n",
       "    0.7890625,\n",
       "    0.79736328125,\n",
       "    0.8017578125,\n",
       "    0.81201171875,\n",
       "    0.8076171875,\n",
       "    0.83251953125,\n",
       "    0.83642578125,\n",
       "    0.828125,\n",
       "    0.8583984375,\n",
       "    0.86083984375,\n",
       "    0.87060546875,\n",
       "    0.884765625,\n",
       "    0.89990234375,\n",
       "    0.89013671875,\n",
       "    0.8740234375,\n",
       "    0.87548828125],\n",
       "   'loss': [0.8633973691612482,\n",
       "    0.7009994462132454,\n",
       "    0.6946569755673409,\n",
       "    0.6895281076431274,\n",
       "    0.6912825778126717,\n",
       "    0.6866499744355679,\n",
       "    0.6920201610773802,\n",
       "    0.6886807959526777,\n",
       "    0.6857946775853634,\n",
       "    0.6874819379299879,\n",
       "    0.6837614960968494,\n",
       "    0.6864820495247841,\n",
       "    0.6829322669655085,\n",
       "    0.6826876290142536,\n",
       "    0.6822668332606554,\n",
       "    0.6826623827219009,\n",
       "    0.6819844245910645,\n",
       "    0.6813588254153728,\n",
       "    0.6814633011817932,\n",
       "    0.6790100298821926,\n",
       "    0.6835517007857561,\n",
       "    0.6779921781271696,\n",
       "    0.6752980519086123,\n",
       "    0.6761874500662088,\n",
       "    0.6840611305087805,\n",
       "    0.6838634703308344,\n",
       "    0.6796542629599571,\n",
       "    0.6751551628112793,\n",
       "    0.6762347016483545,\n",
       "    0.6722020544111729,\n",
       "    0.676500903442502,\n",
       "    0.6651835851371288,\n",
       "    0.6845513377338648,\n",
       "    0.6681285426020622,\n",
       "    0.6618129722774029,\n",
       "    0.6601682715117931,\n",
       "    0.6705440003424883,\n",
       "    0.6693152096122503,\n",
       "    0.6578852999955416,\n",
       "    0.6544293090701103,\n",
       "    0.649696659296751,\n",
       "    0.6575567908585072,\n",
       "    0.6533600259572268,\n",
       "    0.6448727324604988,\n",
       "    0.6357152462005615,\n",
       "    0.6362822875380516,\n",
       "    0.6259165219962597,\n",
       "    0.6195314545184374,\n",
       "    0.6178824584931135,\n",
       "    0.6324192453175783,\n",
       "    0.6152163110673428,\n",
       "    0.600334644317627,\n",
       "    0.5901165958493948,\n",
       "    0.5884726336225867,\n",
       "    0.5701058525592089,\n",
       "    0.5784372994676232,\n",
       "    0.5716706411913037,\n",
       "    0.5780461626127362,\n",
       "    0.54943504370749,\n",
       "    0.5718696946278214,\n",
       "    0.5578855415806174,\n",
       "    0.5227301381528378,\n",
       "    0.519566910341382,\n",
       "    0.5041235201060772,\n",
       "    0.5342354103922844,\n",
       "    0.49021562933921814,\n",
       "    0.4902872424572706,\n",
       "    0.47972829081118107,\n",
       "    0.48238990642130375,\n",
       "    0.4541931701824069,\n",
       "    0.4305404033511877,\n",
       "    0.4242432713508606,\n",
       "    0.41544590797275305,\n",
       "    0.42404321301728487,\n",
       "    0.37938519939780235,\n",
       "    0.37157271802425385,\n",
       "    0.36777944257482886,\n",
       "    0.3326348848640919,\n",
       "    0.318841359578073,\n",
       "    0.30789483431726694,\n",
       "    0.2885198872536421,\n",
       "    0.2750688917003572,\n",
       "    0.27872428437694907,\n",
       "    0.31392765883356333,\n",
       "    0.3182726791128516],\n",
       "   'val_binary_accuracy': [0.498046875,\n",
       "    0.505859375,\n",
       "    0.51171875,\n",
       "    0.525390625,\n",
       "    0.509765625,\n",
       "    0.515625,\n",
       "    0.51171875,\n",
       "    0.525390625,\n",
       "    0.533203125,\n",
       "    0.529296875,\n",
       "    0.52734375,\n",
       "    0.5234375,\n",
       "    0.529296875,\n",
       "    0.533203125,\n",
       "    0.54296875,\n",
       "    0.541015625,\n",
       "    0.53125,\n",
       "    0.55078125,\n",
       "    0.537109375,\n",
       "    0.5546875,\n",
       "    0.521484375,\n",
       "    0.548828125,\n",
       "    0.55078125,\n",
       "    0.50390625,\n",
       "    0.5234375,\n",
       "    0.525390625,\n",
       "    0.5546875,\n",
       "    0.529296875,\n",
       "    0.544921875,\n",
       "    0.53515625,\n",
       "    0.544921875,\n",
       "    0.56640625,\n",
       "    0.544921875,\n",
       "    0.53125,\n",
       "    0.521484375,\n",
       "    0.572265625,\n",
       "    0.517578125,\n",
       "    0.55078125,\n",
       "    0.552734375,\n",
       "    0.576171875,\n",
       "    0.544921875,\n",
       "    0.603515625,\n",
       "    0.580078125,\n",
       "    0.58203125,\n",
       "    0.615234375,\n",
       "    0.603515625,\n",
       "    0.560546875,\n",
       "    0.5703125,\n",
       "    0.62109375,\n",
       "    0.5625,\n",
       "    0.5859375,\n",
       "    0.599609375,\n",
       "    0.630859375,\n",
       "    0.646484375,\n",
       "    0.65625,\n",
       "    0.623046875,\n",
       "    0.650390625,\n",
       "    0.615234375,\n",
       "    0.666015625,\n",
       "    0.623046875,\n",
       "    0.662109375,\n",
       "    0.67578125,\n",
       "    0.66015625,\n",
       "    0.6875,\n",
       "    0.689453125,\n",
       "    0.6640625,\n",
       "    0.640625,\n",
       "    0.654296875,\n",
       "    0.6796875,\n",
       "    0.662109375,\n",
       "    0.669921875,\n",
       "    0.658203125,\n",
       "    0.66015625,\n",
       "    0.673828125,\n",
       "    0.6796875,\n",
       "    0.666015625,\n",
       "    0.66015625,\n",
       "    0.658203125,\n",
       "    0.677734375,\n",
       "    0.685546875,\n",
       "    0.681640625,\n",
       "    0.681640625,\n",
       "    0.671875,\n",
       "    0.650390625,\n",
       "    0.681640625],\n",
       "   'val_loss': [0.6927940249443054,\n",
       "    0.6930646076798439,\n",
       "    0.6930281668901443,\n",
       "    0.6924228891730309,\n",
       "    0.6923955604434013,\n",
       "    0.6920485869050026,\n",
       "    0.6927954405546188,\n",
       "    0.6917137280106544,\n",
       "    0.6916076764464378,\n",
       "    0.6916279718279839,\n",
       "    0.6912299618124962,\n",
       "    0.6914410218596458,\n",
       "    0.6913335919380188,\n",
       "    0.6905320063233376,\n",
       "    0.6905325874686241,\n",
       "    0.6904866322875023,\n",
       "    0.6911981850862503,\n",
       "    0.6883180141448975,\n",
       "    0.6913367882370949,\n",
       "    0.6863595843315125,\n",
       "    0.6899006888270378,\n",
       "    0.6883942484855652,\n",
       "    0.6876120939850807,\n",
       "    0.6918193697929382,\n",
       "    0.6886003240942955,\n",
       "    0.6863295510411263,\n",
       "    0.6873857751488686,\n",
       "    0.6894213631749153,\n",
       "    0.6853406354784966,\n",
       "    0.6855213865637779,\n",
       "    0.6842868775129318,\n",
       "    0.6740126237273216,\n",
       "    0.6861876919865608,\n",
       "    0.687216579914093,\n",
       "    0.6889804527163506,\n",
       "    0.6726962700486183,\n",
       "    0.6993448063731194,\n",
       "    0.6817405596375465,\n",
       "    0.6824047714471817,\n",
       "    0.6669564768671989,\n",
       "    0.6908992901444435,\n",
       "    0.6635167077183723,\n",
       "    0.669126532971859,\n",
       "    0.6622907146811485,\n",
       "    0.6503173634409904,\n",
       "    0.6530374810099602,\n",
       "    0.6940209046006203,\n",
       "    0.7007757499814034,\n",
       "    0.6460386291146278,\n",
       "    0.6670878902077675,\n",
       "    0.6742097958922386,\n",
       "    0.6548792645335197,\n",
       "    0.638092391192913,\n",
       "    0.6327460631728172,\n",
       "    0.6335839554667473,\n",
       "    0.6538863852620125,\n",
       "    0.6402837187051773,\n",
       "    0.6528652459383011,\n",
       "    0.62127635627985,\n",
       "    0.641032986342907,\n",
       "    0.6181562319397926,\n",
       "    0.6187379956245422,\n",
       "    0.6163493916392326,\n",
       "    0.612663522362709,\n",
       "    0.6007981523871422,\n",
       "    0.6228626295924187,\n",
       "    0.6384958773851395,\n",
       "    0.6649596318602562,\n",
       "    0.6334978267550468,\n",
       "    0.6347365342080593,\n",
       "    0.6494990736246109,\n",
       "    0.6551724299788475,\n",
       "    0.6308413073420525,\n",
       "    0.6321359984576702,\n",
       "    0.7006011456251144,\n",
       "    0.6930822879076004,\n",
       "    0.7168662175536156,\n",
       "    0.7342661321163177,\n",
       "    0.7406409308314323,\n",
       "    0.7128252610564232,\n",
       "    0.7870322242379189,\n",
       "    0.8245097398757935,\n",
       "    0.8768421337008476,\n",
       "    0.7897352278232574,\n",
       "    0.8197636306285858]}})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestValScore, index,  bestResult,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6516152462645268,\n",
       " 119,\n",
       " {'config': {'batch_size': 64,\n",
       "   'conv_spatial_filter': [2, 2],\n",
       "   'conv_temporal_filter': [2, 3],\n",
       "   'dropout': 0.25,\n",
       "   'lr': 5e-05,\n",
       "   'max_length': 500,\n",
       "   'max_pool_size': [2, 2],\n",
       "   'max_pool_stride': [1, 2],\n",
       "   'model_name': '4DAA821EEF60686F59016A7FE1452863.h5',\n",
       "   'n_process': 1,\n",
       "   'num_conv_spatial_layers': 7,\n",
       "   'num_conv_temporal_layers': 7,\n",
       "   'num_epochs': 500,\n",
       "   'num_files': None,\n",
       "   'num_spatial_filter': 200,\n",
       "   'num_temporal_filter': 300,\n",
       "   'patience': 20,\n",
       "   'precached_pkl': 'train_data.pkl',\n",
       "   'precached_test_pkl': 'test_data.pkl',\n",
       "   'ref': '01_tcp_ar',\n",
       "   'seed': 44124645,\n",
       "   'test_split': 'dev_test',\n",
       "   'train_split': 'train',\n",
       "   'use_cached_pkl': True,\n",
       "   'use_early_stopping': True,\n",
       "   'use_vp': False,\n",
       "   'validation_size': 0.2},\n",
       "  'bestValScore': 0.6873899772763252,\n",
       "  'testScore': {'acc': 0.7447643979057592,\n",
       "   'auc': 0.6516152462645268,\n",
       "   'f1': 0.8299912816041848},\n",
       "  'history': {'binary_accuracy': [0.50146484375,\n",
       "    0.50439453125,\n",
       "    0.5322265625,\n",
       "    0.52099609375,\n",
       "    0.5244140625,\n",
       "    0.5478515625,\n",
       "    0.529296875,\n",
       "    0.5361328125,\n",
       "    0.52294921875,\n",
       "    0.5458984375,\n",
       "    0.5263671875,\n",
       "    0.54736328125,\n",
       "    0.53857421875,\n",
       "    0.5283203125,\n",
       "    0.53857421875,\n",
       "    0.52587890625,\n",
       "    0.5478515625,\n",
       "    0.53369140625,\n",
       "    0.54296875,\n",
       "    0.53076171875,\n",
       "    0.5556640625,\n",
       "    0.5361328125,\n",
       "    0.54541015625,\n",
       "    0.53173828125,\n",
       "    0.5458984375,\n",
       "    0.5498046875,\n",
       "    0.54296875,\n",
       "    0.52978515625,\n",
       "    0.54833984375,\n",
       "    0.5322265625,\n",
       "    0.537109375,\n",
       "    0.54296875,\n",
       "    0.5390625,\n",
       "    0.5419921875,\n",
       "    0.56689453125,\n",
       "    0.54638671875,\n",
       "    0.544921875,\n",
       "    0.556640625,\n",
       "    0.5556640625,\n",
       "    0.537109375,\n",
       "    0.5498046875,\n",
       "    0.5556640625,\n",
       "    0.560546875,\n",
       "    0.5439453125,\n",
       "    0.5390625,\n",
       "    0.55078125,\n",
       "    0.54052734375,\n",
       "    0.54345703125,\n",
       "    0.5478515625,\n",
       "    0.5517578125,\n",
       "    0.5439453125,\n",
       "    0.55224609375,\n",
       "    0.55859375,\n",
       "    0.5546875,\n",
       "    0.55615234375,\n",
       "    0.54296875,\n",
       "    0.54052734375,\n",
       "    0.55859375,\n",
       "    0.5390625,\n",
       "    0.5517578125,\n",
       "    0.55078125,\n",
       "    0.56005859375,\n",
       "    0.56689453125,\n",
       "    0.56103515625,\n",
       "    0.56298828125,\n",
       "    0.57177734375,\n",
       "    0.56640625,\n",
       "    0.5625,\n",
       "    0.56689453125,\n",
       "    0.5751953125,\n",
       "    0.57470703125,\n",
       "    0.57080078125,\n",
       "    0.5732421875,\n",
       "    0.57470703125,\n",
       "    0.5849609375,\n",
       "    0.57177734375,\n",
       "    0.58447265625,\n",
       "    0.5859375,\n",
       "    0.58935546875,\n",
       "    0.59228515625,\n",
       "    0.583984375,\n",
       "    0.59228515625,\n",
       "    0.5869140625,\n",
       "    0.599609375,\n",
       "    0.59033203125,\n",
       "    0.591796875,\n",
       "    0.5947265625,\n",
       "    0.5810546875,\n",
       "    0.5947265625,\n",
       "    0.5986328125,\n",
       "    0.599609375,\n",
       "    0.59814453125,\n",
       "    0.6044921875,\n",
       "    0.60400390625,\n",
       "    0.60205078125,\n",
       "    0.59814453125,\n",
       "    0.603515625,\n",
       "    0.60400390625,\n",
       "    0.609375,\n",
       "    0.6005859375,\n",
       "    0.59716796875,\n",
       "    0.60400390625,\n",
       "    0.59765625,\n",
       "    0.60888671875,\n",
       "    0.59912109375,\n",
       "    0.60986328125,\n",
       "    0.6181640625,\n",
       "    0.60595703125,\n",
       "    0.611328125,\n",
       "    0.60986328125,\n",
       "    0.61669921875,\n",
       "    0.62109375,\n",
       "    0.62060546875,\n",
       "    0.62109375,\n",
       "    0.6103515625,\n",
       "    0.62060546875],\n",
       "   'loss': [0.889378160238266,\n",
       "    0.74490169249475,\n",
       "    0.7181401867419481,\n",
       "    0.7107755858451128,\n",
       "    0.7059345729649067,\n",
       "    0.697337893769145,\n",
       "    0.7033549379557371,\n",
       "    0.7028186582028866,\n",
       "    0.6972027756273746,\n",
       "    0.6951018031686544,\n",
       "    0.6941796336323023,\n",
       "    0.6941238325089216,\n",
       "    0.6908664703369141,\n",
       "    0.698113551363349,\n",
       "    0.6939773093909025,\n",
       "    0.6914632897824049,\n",
       "    0.6936530321836472,\n",
       "    0.6915866397321224,\n",
       "    0.6988398376852274,\n",
       "    0.6916992235928774,\n",
       "    0.6928504873067141,\n",
       "    0.6910957675427198,\n",
       "    0.69054532982409,\n",
       "    0.6942062266170979,\n",
       "    0.6908074580132961,\n",
       "    0.6883600018918514,\n",
       "    0.6926102507859468,\n",
       "    0.6922213174402714,\n",
       "    0.6941887214779854,\n",
       "    0.6908529866486788,\n",
       "    0.6889176424592733,\n",
       "    0.689574096351862,\n",
       "    0.6893378309905529,\n",
       "    0.6894046477973461,\n",
       "    0.6868970971554518,\n",
       "    0.6887451577931643,\n",
       "    0.6853288542479277,\n",
       "    0.6834850050508976,\n",
       "    0.6887136641889811,\n",
       "    0.6889305617660284,\n",
       "    0.6846742238849401,\n",
       "    0.685120427981019,\n",
       "    0.6853081714361906,\n",
       "    0.6883818153291941,\n",
       "    0.682657765224576,\n",
       "    0.6808271706104279,\n",
       "    0.6839026249945164,\n",
       "    0.6844237055629492,\n",
       "    0.6801463570445776,\n",
       "    0.6843121107667685,\n",
       "    0.6832696683704853,\n",
       "    0.6840761918574572,\n",
       "    0.6839441973716021,\n",
       "    0.6819606889039278,\n",
       "    0.683062294498086,\n",
       "    0.6825484670698643,\n",
       "    0.6813803482800722,\n",
       "    0.6815952397882938,\n",
       "    0.677863547578454,\n",
       "    0.6847090888768435,\n",
       "    0.6800007428973913,\n",
       "    0.6818439997732639,\n",
       "    0.6836751624941826,\n",
       "    0.6797881163656712,\n",
       "    0.6823465563356876,\n",
       "    0.6812375579029322,\n",
       "    0.6795432344079018,\n",
       "    0.6786250304430723,\n",
       "    0.6778373960405588,\n",
       "    0.6785685457289219,\n",
       "    0.6782331094145775,\n",
       "    0.6782258860766888,\n",
       "    0.6769963409751654,\n",
       "    0.6797889936715364,\n",
       "    0.6759148370474577,\n",
       "    0.6787260062992573,\n",
       "    0.6763947512954473,\n",
       "    0.6765005048364401,\n",
       "    0.6759508829563856,\n",
       "    0.6758631952106953,\n",
       "    0.674263522028923,\n",
       "    0.6721483375877142,\n",
       "    0.6764595005661249,\n",
       "    0.6740618646144867,\n",
       "    0.6725206449627876,\n",
       "    0.675842247903347,\n",
       "    0.6721528228372335,\n",
       "    0.6714777108281851,\n",
       "    0.6741716451942921,\n",
       "    0.6702610235661268,\n",
       "    0.665852427482605,\n",
       "    0.6666942220181227,\n",
       "    0.6641772203147411,\n",
       "    0.6674255207180977,\n",
       "    0.6656815372407436,\n",
       "    0.6666395086795092,\n",
       "    0.6656454894691706,\n",
       "    0.6596364174038172,\n",
       "    0.6601045168936253,\n",
       "    0.660445911809802,\n",
       "    0.659669516608119,\n",
       "    0.6572497468441725,\n",
       "    0.6616646610200405,\n",
       "    0.6612966023385525,\n",
       "    0.6595934610813856,\n",
       "    0.6585913877934217,\n",
       "    0.6516276281327009,\n",
       "    0.6563218273222446,\n",
       "    0.6581460442394018,\n",
       "    0.6540955491364002,\n",
       "    0.6496928408741951,\n",
       "    0.6457185205072165,\n",
       "    0.6492960881441832,\n",
       "    0.6432762090116739,\n",
       "    0.6576373558491468,\n",
       "    0.6490295901894569],\n",
       "   'val_binary_accuracy': [0.501953125,\n",
       "    0.50390625,\n",
       "    0.498046875,\n",
       "    0.5,\n",
       "    0.50390625,\n",
       "    0.505859375,\n",
       "    0.505859375,\n",
       "    0.505859375,\n",
       "    0.50390625,\n",
       "    0.5,\n",
       "    0.498046875,\n",
       "    0.50390625,\n",
       "    0.51171875,\n",
       "    0.501953125,\n",
       "    0.49609375,\n",
       "    0.498046875,\n",
       "    0.509765625,\n",
       "    0.501953125,\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.505859375,\n",
       "    0.501953125,\n",
       "    0.5,\n",
       "    0.513671875,\n",
       "    0.501953125,\n",
       "    0.494140625,\n",
       "    0.50390625,\n",
       "    0.505859375,\n",
       "    0.494140625,\n",
       "    0.5,\n",
       "    0.50390625,\n",
       "    0.5078125,\n",
       "    0.505859375,\n",
       "    0.515625,\n",
       "    0.505859375,\n",
       "    0.51171875,\n",
       "    0.5078125,\n",
       "    0.505859375,\n",
       "    0.513671875,\n",
       "    0.509765625,\n",
       "    0.517578125,\n",
       "    0.53125,\n",
       "    0.525390625,\n",
       "    0.5078125,\n",
       "    0.51953125,\n",
       "    0.53125,\n",
       "    0.5234375,\n",
       "    0.525390625,\n",
       "    0.541015625,\n",
       "    0.5234375,\n",
       "    0.5859375,\n",
       "    0.51171875,\n",
       "    0.54296875,\n",
       "    0.53515625,\n",
       "    0.513671875,\n",
       "    0.521484375,\n",
       "    0.541015625,\n",
       "    0.546875,\n",
       "    0.53515625,\n",
       "    0.525390625,\n",
       "    0.54296875,\n",
       "    0.515625,\n",
       "    0.525390625,\n",
       "    0.515625,\n",
       "    0.521484375,\n",
       "    0.501953125,\n",
       "    0.5234375,\n",
       "    0.544921875,\n",
       "    0.515625,\n",
       "    0.5078125,\n",
       "    0.521484375,\n",
       "    0.53125,\n",
       "    0.525390625,\n",
       "    0.5234375,\n",
       "    0.52734375,\n",
       "    0.498046875,\n",
       "    0.51171875,\n",
       "    0.51953125,\n",
       "    0.521484375,\n",
       "    0.5234375,\n",
       "    0.521484375,\n",
       "    0.517578125,\n",
       "    0.505859375,\n",
       "    0.52734375,\n",
       "    0.515625,\n",
       "    0.5234375,\n",
       "    0.509765625,\n",
       "    0.52734375,\n",
       "    0.5390625,\n",
       "    0.525390625,\n",
       "    0.533203125,\n",
       "    0.533203125,\n",
       "    0.515625,\n",
       "    0.537109375,\n",
       "    0.52734375,\n",
       "    0.54296875,\n",
       "    0.537109375,\n",
       "    0.53515625,\n",
       "    0.533203125,\n",
       "    0.52734375,\n",
       "    0.5390625,\n",
       "    0.51953125,\n",
       "    0.529296875,\n",
       "    0.529296875,\n",
       "    0.5234375,\n",
       "    0.533203125,\n",
       "    0.525390625,\n",
       "    0.5234375,\n",
       "    0.51953125,\n",
       "    0.525390625,\n",
       "    0.537109375,\n",
       "    0.533203125,\n",
       "    0.517578125,\n",
       "    0.513671875,\n",
       "    0.52734375,\n",
       "    0.53125],\n",
       "   'val_loss': [0.6931604966521263,\n",
       "    0.6930863931775093,\n",
       "    0.6930964142084122,\n",
       "    0.6931096613407135,\n",
       "    0.6930713951587677,\n",
       "    0.6930277273058891,\n",
       "    0.6930600702762604,\n",
       "    0.6930617615580559,\n",
       "    0.6931023821234703,\n",
       "    0.6931472048163414,\n",
       "    0.6931586265563965,\n",
       "    0.6930589899420738,\n",
       "    0.6928680911660194,\n",
       "    0.6932259574532509,\n",
       "    0.693343423306942,\n",
       "    0.693179614841938,\n",
       "    0.6929276511073112,\n",
       "    0.6931527778506279,\n",
       "    0.6932092905044556,\n",
       "    0.6931077539920807,\n",
       "    0.6929853484034538,\n",
       "    0.6930621936917305,\n",
       "    0.6931320279836655,\n",
       "    0.6927383691072464,\n",
       "    0.6931145638227463,\n",
       "    0.6932854056358337,\n",
       "    0.6930493861436844,\n",
       "    0.6929797977209091,\n",
       "    0.6932998225092888,\n",
       "    0.6931073516607285,\n",
       "    0.6928939521312714,\n",
       "    0.692739337682724,\n",
       "    0.6926579996943474,\n",
       "    0.6924081966280937,\n",
       "    0.6924488842487335,\n",
       "    0.692446805536747,\n",
       "    0.6923068314790726,\n",
       "    0.6921155452728271,\n",
       "    0.6921015605330467,\n",
       "    0.6920916214585304,\n",
       "    0.6919267922639847,\n",
       "    0.6915254965424538,\n",
       "    0.692024402320385,\n",
       "    0.6916708946228027,\n",
       "    0.6915066689252853,\n",
       "    0.6910148710012436,\n",
       "    0.6915339678525925,\n",
       "    0.6919099166989326,\n",
       "    0.6908127889037132,\n",
       "    0.691608615219593,\n",
       "    0.6914301067590714,\n",
       "    0.6919994503259659,\n",
       "    0.691532552242279,\n",
       "    0.6915396153926849,\n",
       "    0.6914807483553886,\n",
       "    0.6909895837306976,\n",
       "    0.6908591315150261,\n",
       "    0.691089503467083,\n",
       "    0.6901430189609528,\n",
       "    0.6914069652557373,\n",
       "    0.691140204668045,\n",
       "    0.6913451850414276,\n",
       "    0.6915002018213272,\n",
       "    0.6916597560048103,\n",
       "    0.6913798451423645,\n",
       "    0.6919288486242294,\n",
       "    0.6908353492617607,\n",
       "    0.6902706548571587,\n",
       "    0.6907089650630951,\n",
       "    0.6916614547371864,\n",
       "    0.6903046667575836,\n",
       "    0.6892788335680962,\n",
       "    0.6906472519040108,\n",
       "    0.6910752952098846,\n",
       "    0.689981609582901,\n",
       "    0.6920658275485039,\n",
       "    0.6910822987556458,\n",
       "    0.6902864575386047,\n",
       "    0.6908826380968094,\n",
       "    0.690468043088913,\n",
       "    0.6913775205612183,\n",
       "    0.6907476186752319,\n",
       "    0.6925128474831581,\n",
       "    0.6896934285759926,\n",
       "    0.6915053352713585,\n",
       "    0.6907005235552788,\n",
       "    0.6927990466356277,\n",
       "    0.6891748607158661,\n",
       "    0.6895812600851059,\n",
       "    0.691129595041275,\n",
       "    0.6889945864677429,\n",
       "    0.6907913312315941,\n",
       "    0.694338247179985,\n",
       "    0.6895735785365105,\n",
       "    0.6945352479815483,\n",
       "    0.6873899772763252,\n",
       "    0.6900515928864479,\n",
       "    0.6921176016330719,\n",
       "    0.691783644258976,\n",
       "    0.6960372477769852,\n",
       "    0.691666379570961,\n",
       "    0.7023968622088432,\n",
       "    0.6938269063830376,\n",
       "    0.6942945271730423,\n",
       "    0.7011306881904602,\n",
       "    0.694481335580349,\n",
       "    0.7066795825958252,\n",
       "    0.6963014230132103,\n",
       "    0.7077841460704803,\n",
       "    0.7005334347486496,\n",
       "    0.6897431686520576,\n",
       "    0.6934866309165955,\n",
       "    0.6986417770385742,\n",
       "    0.7133344560861588,\n",
       "    0.6908251792192459,\n",
       "    0.6896934881806374]}})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestCheatScore, cheatIndex, bestCheatResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sbatch -n 1 --mem-per-cpu 32G -t 12:00:00 -p gpu --gres=gpu:1 run.sh use_vp=False lr=0.001 num_spatial_filter=300 num_temporal_filter=300 num_conv_spatial_layers=7 num_conv_temporal_layers=7 num_epochs=100 patience=20 conv_spatial_filter_3_3 conv_temporal_filter_2_3 use_cached_pkl=True model_name=$(hexdump -n 16 -e '4/4 \"%08X\" 1 \"\\n\"' /dev/urandom).h5 simple_ensemble_samples n_process=8 batch_size=32 -D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': 2934,\n",
       " 'experiment': {'name': 'gender_predict_conv_gridsearch',\n",
       "  'base_dir': '/home/ms994/dbmi_eeg_clustering',\n",
       "  'sources': [['clinical_text_analysis.py',\n",
       "    ObjectId('5d2d5864eadb9a19a004b3ab')],\n",
       "   ['constants.py', ObjectId('5d27d20008dbf0f57da81b62')],\n",
       "   ['data_reader.py', ObjectId('5d2e0f3d396ada4c0d3e0c00')],\n",
       "   ['keras_models/__init__.py', ObjectId('5d2c2b93fc0fc7746d130fa5')],\n",
       "   ['keras_models/dataGen.py', ObjectId('5d2d5865eadb9a19a004b3af')],\n",
       "   ['keras_models/vanPutten.py', ObjectId('5d2df305fc0fc77d11b17dcf')],\n",
       "   ['predictGenderConvExp.py', ObjectId('5d2e3551396ada0cd357686e')],\n",
       "   ['util_funcs.py', ObjectId('5d2e0d9deadb9a2f3caf61c0')],\n",
       "   ['wf_analysis/__init__.py', ObjectId('5d24f280bef7d40ea2ab7519')],\n",
       "   ['wf_analysis/datasets.py', ObjectId('5d293e67f2bc6e6e86d41863')]],\n",
       "  'dependencies': ['addict==2.2.1',\n",
       "   'Keras==2.2.4',\n",
       "   'numpy==1.16.2',\n",
       "   'pandas==0.24.2',\n",
       "   'sacred==0.7.5',\n",
       "   'scikit-learn==0.20.3'],\n",
       "  'repositories': [{'url': 'git@github.com:Saqibm128/dbmi_eeg_clustering.git',\n",
       "    'commit': '68f9fdf7cec5f0b8341766fe20d56bd478ebfa97',\n",
       "    'dirty': False},\n",
       "   {'url': 'git@github.com:Saqibm128/dbmi_eeg_clustering.git',\n",
       "    'commit': '68f9fdf7cec5f0b8341766fe20d56bd478ebfa97',\n",
       "    'dirty': False},\n",
       "   {'url': 'git@github.com:Saqibm128/dbmi_eeg_clustering.git',\n",
       "    'commit': '68f9fdf7cec5f0b8341766fe20d56bd478ebfa97',\n",
       "    'dirty': False},\n",
       "   {'url': 'git@github.com:Saqibm128/dbmi_eeg_clustering.git',\n",
       "    'commit': '68f9fdf7cec5f0b8341766fe20d56bd478ebfa97',\n",
       "    'dirty': False},\n",
       "   {'url': 'git@github.com:Saqibm128/dbmi_eeg_clustering.git',\n",
       "    'commit': '68f9fdf7cec5f0b8341766fe20d56bd478ebfa97',\n",
       "    'dirty': False},\n",
       "   {'url': 'git@github.com:Saqibm128/dbmi_eeg_clustering.git',\n",
       "    'commit': '68f9fdf7cec5f0b8341766fe20d56bd478ebfa97',\n",
       "    'dirty': False},\n",
       "   {'url': 'git@github.com:Saqibm128/dbmi_eeg_clustering.git',\n",
       "    'commit': '68f9fdf7cec5f0b8341766fe20d56bd478ebfa97',\n",
       "    'dirty': False},\n",
       "   {'url': 'git@github.com:Saqibm128/dbmi_eeg_clustering.git',\n",
       "    'commit': '68f9fdf7cec5f0b8341766fe20d56bd478ebfa97',\n",
       "    'dirty': False},\n",
       "   {'url': 'git@github.com:Saqibm128/dbmi_eeg_clustering.git',\n",
       "    'commit': '68f9fdf7cec5f0b8341766fe20d56bd478ebfa97',\n",
       "    'dirty': False},\n",
       "   {'url': 'git@github.com:Saqibm128/dbmi_eeg_clustering.git',\n",
       "    'commit': '68f9fdf7cec5f0b8341766fe20d56bd478ebfa97',\n",
       "    'dirty': False}],\n",
       "  'mainfile': 'predictGenderConvExp.py'},\n",
       " 'format': 'MongoObserver-0.7.0',\n",
       " 'command': 'main',\n",
       " 'host': {'hostname': 'compute-g-16-176.o2.rc.hms.harvard.edu',\n",
       "  'os': ['Linux',\n",
       "   'Linux-3.10.0-327.3.1.el7.x86_64-x86_64-with-centos-7.2.1511-Core'],\n",
       "  'python_version': '3.7.3',\n",
       "  'cpu': 'Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz',\n",
       "  'gpus': {'gpus': [{'model': 'Tesla M40',\n",
       "     'total_memory': 11448,\n",
       "     'persistence_mode': False},\n",
       "    {'model': 'Tesla M40', 'total_memory': 11448, 'persistence_mode': False},\n",
       "    {'model': 'Tesla M40', 'total_memory': 11448, 'persistence_mode': False},\n",
       "    {'model': 'Tesla M40', 'total_memory': 11448, 'persistence_mode': False}],\n",
       "   'driver_version': '410.48'},\n",
       "  'ENV': {}},\n",
       " 'start_time': datetime.datetime(2019, 7, 16, 20, 36, 32, 867000),\n",
       " 'config': {'batch_size': 64,\n",
       "  'conv_spatial_filter': [2, 2],\n",
       "  'conv_temporal_filter': [1, 7],\n",
       "  'dropout': 0.25,\n",
       "  'lr': 0.0001,\n",
       "  'max_length': 500,\n",
       "  'max_pool_size': [2, 2],\n",
       "  'max_pool_stride': [1, 2],\n",
       "  'model_name': 'AC7009C49B32C89DFE03EF7B8D47C53D.h5',\n",
       "  'n_process': 6,\n",
       "  'num_conv_spatial_layers': 1,\n",
       "  'num_conv_temporal_layers': 1,\n",
       "  'num_epochs': 500,\n",
       "  'num_files': None,\n",
       "  'num_spatial_filter': 200,\n",
       "  'num_temporal_filter': 300,\n",
       "  'patience': 20,\n",
       "  'precached_pkl': 'train_data.pkl',\n",
       "  'precached_test_pkl': 'test_data.pkl',\n",
       "  'ref': '01_tcp_ar',\n",
       "  'seed': 247811920,\n",
       "  'test_split': 'dev_test',\n",
       "  'train_split': 'train',\n",
       "  'use_cached_pkl': True,\n",
       "  'use_early_stopping': True,\n",
       "  'use_vp': False,\n",
       "  'validation_size': 0.2},\n",
       " 'meta': {'command': 'main',\n",
       "  'options': {'--mongo_db': None,\n",
       "   '--sql': None,\n",
       "   '--beat_interval': None,\n",
       "   '--pdb': False,\n",
       "   '--queue': False,\n",
       "   '--enforce_clean': False,\n",
       "   '--loglevel': None,\n",
       "   '--unobserved': False,\n",
       "   '--capture': None,\n",
       "   '--priority': None,\n",
       "   '--print_config': False,\n",
       "   '--force': False,\n",
       "   '--file_storage': None,\n",
       "   '--name': None,\n",
       "   '--debug': False,\n",
       "   '--comment': None,\n",
       "   '--tiny_db': None,\n",
       "   '--help': False,\n",
       "   'with': True,\n",
       "   'UPDATE': ['model_name=AC7009C49B32C89DFE03EF7B8D47C53D.h5',\n",
       "    'n_process=6',\n",
       "    'use_vp=False',\n",
       "    'num_conv_spatial_layers=1',\n",
       "    'num_conv_temporal_layers=1',\n",
       "    'conv_spatial_filter_2_2',\n",
       "    'num_spatial_filter=200',\n",
       "    'conv_temporal_filter_1_7'],\n",
       "   'help': False,\n",
       "   'COMMAND': None}},\n",
       " 'status': 'COMPLETED',\n",
       " 'resources': [],\n",
       " 'artifacts': [],\n",
       " 'captured_out': 'INFO - gender_predict_conv_gridsearch - Running command \\'main\\'\\nINFO - gender_predict_conv_gridsearch - Started run with ID \"2934\"\\nStarting 6 processes\\nretrieving: 0\\nretrieving: 10\\nretrieving: 20\\nretrieving: 30\\nretrieving: 40\\nretrieving: 50\\nretrieving: 60\\nretrieving: 70\\nretrieving: 80\\nretrieving: 90\\nretrieving: 100\\nretrieving: 110\\nretrieving: 120\\nretrieving: 130\\nretrieving: 140\\nretrieving: 150\\nretrieving: 160\\nretrieving: 170\\nretrieving: 180\\nretrieving: 190\\nretrieving: 200\\nretrieving: 210\\nretrieving: 220\\nretrieving: 230\\nretrieving: 240\\nretrieving: 250\\nretrieving: 260\\nretrieving: 270\\nretrieving: 280\\nretrieving: 290\\nretrieving: 300\\nretrieving: 310\\nretrieving: 320\\nretrieving: 330\\nretrieving: 340\\nretrieving: 350\\nretrieving: 360\\nretrieving: 370\\nretrieving: 380\\nretrieving: 390\\nretrieving: 400\\nretrieving: 410\\nretrieving: 420\\nretrieving: 430\\nretrieving: 440\\nretrieving: 450\\nretrieving: 460\\nretrieving: 470\\nretrieving: 480\\nretrieving: 490\\nretrieving: 500\\nretrieving: 510\\nretrieving: 520\\nretrieving: 530\\nretrieving: 540\\nretrieving: 550\\nretrieving: 560\\nretrieving: 570\\nretrieving: 580\\nretrieving: 590\\nretrieving: 600\\nretrieving: 610\\nretrieving: 620\\nretrieving: 630\\nretrieving: 640\\nretrieving: 650\\nretrieving: 660\\nretrieving: 670\\nretrieving: 680\\nretrieving: 690\\nretrieving: 700\\nretrieving: 710\\nretrieving: 720\\nretrieving: 730\\nretrieving: 740\\nretrieving: 750\\nretrieving: 760\\nretrieving: 770\\nretrieving: 780\\nretrieving: 790\\nretrieving: 800\\nretrieving: 810\\nretrieving: 820\\nretrieving: 830\\nretrieving: 840\\nretrieving: 850\\nretrieving: 860\\nretrieving: 870\\nretrieving: 880\\nretrieving: 890\\nretrieving: 900\\nretrieving: 910\\nretrieving: 920\\nretrieving: 930\\nretrieving: 940\\nretrieving: 950\\nretrieving: 960\\nretrieving: 970\\nretrieving: 980\\nretrieving: 990\\nretrieving: 1000\\nretrieving: 1010\\nretrieving: 1020\\nretrieving: 1030\\nretrieving: 1040\\nretrieving: 1050\\nretrieving: 1060\\nretrieving: 1070\\nretrieving: 1080\\nretrieving: 1090\\nretrieving: 1100\\nretrieving: 1110\\nretrieving: 1120\\nretrieving: 1130\\nretrieving: 1140\\nretrieving: 1150\\nretrieving: 1160\\nretrieving: 1170\\nretrieving: 1180\\nretrieving: 1190\\nretrieving: 1200\\nretrieving: 1210\\nretrieving: 1220\\nretrieving: 1230\\nretrieving: 1240\\nretrieving: 1250\\nretrieving: 1260\\nretrieving: 1270\\nretrieving: 1280\\nretrieving: 1290\\nretrieving: 1300\\nretrieving: 1310\\nretrieving: 1320\\nretrieving: 1330\\nretrieving: 1340\\nretrieving: 1350\\nretrieving: 1360\\nretrieving: 1370\\nretrieving: 1380\\nretrieving: 1390\\nretrieving: 1400\\nretrieving: 1410\\nretrieving: 1420\\nretrieving: 1430\\nretrieving: 1440\\nretrieving: 1450\\nretrieving: 1460\\nretrieving: 1470\\nretrieving: 1480\\nretrieving: 1490\\nretrieving: 1500\\nretrieving: 1510\\nretrieving: 1520\\nretrieving: 1530\\nretrieving: 1540\\nretrieving: 1550\\nretrieving: 1560\\nretrieving: 1570\\nretrieving: 1580\\nretrieving: 1590\\nretrieving: 1600\\nretrieving: 1610\\nretrieving: 1620\\nretrieving: 1630\\nretrieving: 1640\\nretrieving: 1650\\nretrieving: 1660\\nretrieving: 1670\\nretrieving: 1680\\nretrieving: 1690\\nretrieving: 1700\\nretrieving: 1710\\nretrieving: 1720\\nretrieving: 1730\\nretrieving: 1740\\nretrieving: 1750\\nretrieving: 1760\\nretrieving: 1770\\nretrieving: 1780\\nretrieving: 1790\\nretrieving: 1800\\nretrieving: 1810\\nretrieving: 1820\\nretrieving: 1830\\nretrieving: 1840\\nretrieving: 1850\\nretrieving: 1860\\nretrieving: 1870\\nretrieving: 1880\\nretrieving: 1890\\nretrieving: 1900\\nretrieving: 1910\\nretrieving: 1920\\nretrieving: 1930\\nretrieving: 1940\\nretrieving: 1950\\nretrieving: 1960\\nretrieving: 1970\\nretrieving: 1980\\nretrieving: 1990\\nretrieving: 2000\\nretrieving: 2010\\nretrieving: 2020\\nretrieving: 2030\\nretrieving: 2040\\nretrieving: 2050\\nretrieving: 2060\\nretrieving: 2070\\nretrieving: 2080\\nretrieving: 2090\\nretrieving: 2100\\nretrieving: 2110\\nretrieving: 2120\\nretrieving: 2130\\nretrieving: 2140\\nretrieving: 2150\\nretrieving: 2160\\nretrieving: 2170\\nretrieving: 2180\\nretrieving: 2190\\nretrieving: 2200\\nretrieving: 2210\\nretrieving: 2220\\nretrieving: 2230\\nretrieving: 2240\\nretrieving: 2250\\nretrieving: 2260\\nretrieving: 2270\\nretrieving: 2280\\nretrieving: 2290\\nretrieving: 2300\\nretrieving: 2310\\nretrieving: 2320\\nretrieving: 2330\\nretrieving: 2340\\nretrieving: 2350\\nretrieving: 2360\\nretrieving: 2370\\nretrieving: 2380\\nretrieving: 2390\\nretrieving: 2400\\nretrieving: 2410\\nretrieving: 2420\\nretrieving: 2430\\nretrieving: 2440\\nretrieving: 2450\\nretrieving: 2460\\nretrieving: 2470\\nretrieving: 2480\\nretrieving: 2490\\nretrieving: 2500\\nretrieving: 2510\\nretrieving: 2520\\nretrieving: 2530\\nretrieving: 2540\\nretrieving: 2550\\nretrieving: 2560\\nretrieving: 2570\\nretrieving: 2580\\nretrieving: 2590\\nretrieving: 2600\\nretrieving: 2610\\nWARNING - tensorflow - From /home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\\nInstructions for updating:\\nColocations handled automatically by placer.\\nWARNING - tensorflow - From /home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\\nInstructions for updating:\\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\\n2019-07-16 16:38:51.997806: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\\n2019-07-16 16:38:52.004820: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299945000 Hz\\n2019-07-16 16:38:52.005131: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x7fecec4b7240 executing computations on platform Host. Devices:\\n2019-07-16 16:38:52.005153: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\\n2019-07-16 16:38:59.292664: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x7fecec5634c0 executing computations on platform CUDA. Devices:\\n2019-07-16 16:38:59.292693: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla M40, Compute Capability 5.2\\n2019-07-16 16:38:59.293502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \\nname: Tesla M40 major: 5 minor: 2 memoryClockRate(GHz): 1.112\\npciBusID: 0000:03:00.0\\ntotalMemory: 11.18GiB freeMemory: 11.07GiB\\n2019-07-16 16:38:59.293529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\\n2019-07-16 16:38:59.298276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\\n2019-07-16 16:38:59.298293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \\n2019-07-16 16:38:59.298299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \\n2019-07-16 16:38:59.298703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10766 MB memory) -> physical GPU (device: 0, name: Tesla M40, pci bus id: 0000:03:00.0, compute capability: 5.2)\\n2019-07-16 16:39:00.187908: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\\nWARNING - tensorflow - From /home/ms994/miniconda3/envs/keras-redo/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\\nInstructions for updating:\\nUse tf.cast instead.\\nEpoch 1/500\\n\\n 1/32 [..............................] - ETA: 1:00 - loss: 4.6096 - binary_accuracy: 0.4688\\n 2/32 [>.............................] - ETA: 34s - loss: 7.3417 - binary_accuracy: 0.4219 \\n 3/32 [=>............................] - ETA: 26s - loss: 6.9932 - binary_accuracy: 0.4844\\n 4/32 [==>...........................] - ETA: 21s - loss: 7.1337 - binary_accuracy: 0.4961\\n 5/32 [===>..........................] - ETA: 18s - loss: 7.2684 - binary_accuracy: 0.5000\\n 6/32 [====>.........................] - ETA: 16s - loss: 7.4422 - binary_accuracy: 0.4974\\n 7/32 [=====>........................] - ETA: 14s - loss: 7.5303 - binary_accuracy: 0.4978\\n 8/32 [======>.......................] - ETA: 13s - loss: 7.7538 - binary_accuracy: 0.4883\\n 9/32 [=======>......................] - ETA: 12s - loss: 7.7038 - binary_accuracy: 0.4948\\n10/32 [========>.....................] - ETA: 11s - loss: 7.8148 - binary_accuracy: 0.4906\\n11/32 [=========>....................] - ETA: 10s - loss: 7.8599 - binary_accuracy: 0.4901\\n12/32 [==========>...................] - ETA: 10s - loss: 7.8555 - binary_accuracy: 0.4922\\n13/32 [===========>..................] - ETA: 9s - loss: 7.9099 - binary_accuracy: 0.4904 \\n14/32 [============>.................] - ETA: 8s - loss: 7.9026 - binary_accuracy: 0.4922\\n15/32 [=============>................] - ETA: 8s - loss: 7.8795 - binary_accuracy: 0.4948\\n16/32 [==============>...............] - ETA: 7s - loss: 7.9694 - binary_accuracy: 0.4902\\n17/32 [==============>...............] - ETA: 6s - loss: 7.9450 - binary_accuracy: 0.4926\\n18/32 [===============>..............] - ETA: 6s - loss: 7.8954 - binary_accuracy: 0.4965\\n19/32 [================>.............] - ETA: 5s - loss: 7.9173 - binary_accuracy: 0.4959\\n20/32 [=================>............] - ETA: 5s - loss: 7.9244 - binary_accuracy: 0.4961\\n21/32 [==================>...........] - ETA: 4s - loss: 7.9907 - binary_accuracy: 0.4926\\n22/32 [===================>..........] - ETA: 4s - loss: 8.0167 - binary_accuracy: 0.4915\\n23/32 [====================>.........] - ETA: 3s - loss: 7.9748 - binary_accuracy: 0.4946\\n24/32 [=====================>........] - ETA: 3s - loss: 7.9363 - binary_accuracy: 0.4974\\n25/32 [======================>.......] - ETA: 3s - loss: 7.9211 - binary_accuracy: 0.4988\\n26/32 [=======================>......] - ETA: 2s - loss: 7.8876 - binary_accuracy: 0.5012\\n27/32 [========================>.....] - ETA: 2s - loss: 7.8567 - binary_accuracy: 0.5035\\n28/32 [=========================>....] - ETA: 1s - loss: 7.8459 - binary_accuracy: 0.5045\\n29/32 [==========================>...] - ETA: 1s - loss: 7.8446 - binary_accuracy: 0.5048\\n30/32 [===========================>..] - ETA: 0s - loss: 7.8349 - binary_accuracy: 0.5057\\n31/32 [============================>.] - ETA: 0s - loss: 7.8665 - binary_accuracy: 0.5040\\n32/32 [==============================] - 14s 441ms/step - loss: 7.9119 - binary_accuracy: 0.5015 - val_loss: 7.9961 - val_binary_accuracy: 0.5039\\n\\nEpoch 00001: val_loss improved from inf to 7.99609, saving model to AC7009C49B32C89DFE03EF7B8D47C53D.h5\\nEpoch 2/500\\n\\n 1/32 [..............................] - ETA: 11s - loss: 8.5627 - binary_accuracy: 0.4688\\n 2/32 [>.............................] - ETA: 11s - loss: 8.8146 - binary_accuracy: 0.4531\\n 3/32 [=>............................] - ETA: 10s - loss: 8.3948 - binary_accuracy: 0.4792\\n 4/32 [==>...........................] - ETA: 10s - loss: 8.6257 - binary_accuracy: 0.4648\\n 5/32 [===>..........................] - ETA: 9s - loss: 8.5124 - binary_accuracy: 0.4719 \\n 6/32 [====>.........................] - ETA: 9s - loss: 8.4368 - binary_accuracy: 0.4766\\n 7/32 [=====>........................] - ETA: 9s - loss: 8.5268 - binary_accuracy: 0.4710\\n 8/32 [======>.......................] - ETA: 8s - loss: 8.3109 - binary_accuracy: 0.4844\\n 9/32 [=======>......................] - ETA: 8s - loss: 8.3389 - binary_accuracy: 0.4826\\n10/32 [========>.....................] - ETA: 8s - loss: 8.1850 - binary_accuracy: 0.4922\\n11/32 [=========>....................] - ETA: 7s - loss: 8.1048 - binary_accuracy: 0.4972\\n12/32 [==========>...................] - ETA: 7s - loss: 8.0381 - binary_accuracy: 0.5013\\n13/32 [===========>..................] - ETA: 7s - loss: 8.0203 - binary_accuracy: 0.5024\\n14/32 [============>.................] - ETA: 6s - loss: 8.0590 - binary_accuracy: 0.5000\\n15/32 [=============>................] - ETA: 6s - loss: 8.1262 - binary_accuracy: 0.4958\\n16/32 [==============>...............] - ETA: 5s - loss: 8.0905 - binary_accuracy: 0.4980\\n17/32 [==============>...............] - ETA: 5s - loss: 8.0590 - binary_accuracy: 0.5000\\n18/32 [===============>..............] - ETA: 5s - loss: 8.0730 - binary_accuracy: 0.4991\\n19/32 [================>.............] - ETA: 4s - loss: 8.1386 - binary_accuracy: 0.4951\\n20/32 [=================>............] - ETA: 4s - loss: 8.1850 - binary_accuracy: 0.4922\\n21/32 [==================>...........] - ETA: 4s - loss: 8.1310 - binary_accuracy: 0.4955\\n22/32 [===================>..........] - ETA: 3s - loss: 8.1163 - binary_accuracy: 0.4964\\n23/32 [====================>.........] - ETA: 3s - loss: 8.1466 - binary_accuracy: 0.4946\\n24/32 [=====================>........] - ETA: 2s - loss: 8.1220 - binary_accuracy: 0.4961\\n25/32 [======================>.......] - ETA: 2s - loss: 8.0691 - binary_accuracy: 0.4994\\n26/32 [=======================>......] - ETA: 2s - loss: 8.0784 - binary_accuracy: 0.4988\\n27/32 [========================>.....] - ETA: 1s - loss: 8.0217 - binary_accuracy: 0.5023\\n28/32 [=========================>....] - ETA: 1s - loss: 8.0051 - binary_accuracy: 0.5033\\n29/32 [==========================>...] - ETA: 1s - loss: 7.9896 - binary_accuracy: 0.5043\\n30/32 [===========================>..] - ETA: 0s - loss: 7.9835 - binary_accuracy: 0.5047\\n31/32 [============================>.] - ETA: 0s - loss: 7.9859 - binary_accuracy: 0.5045\\n32/32 [==============================] - 12s 390ms/step - loss: 8.0118 - binary_accuracy: 0.5029 - val_loss: 8.0276 - val_binary_accuracy: 0.5020\\n\\nEpoch 00002: val_loss did not improve from 7.99609\\nEpoch 3/500\\n\\n 1/32 [..............................] - ETA: 11s - loss: 8.8146 - binary_accuracy: 0.4531\\n 2/32 [>.............................] - ETA: 11s - loss: 8.9405 - binary_accuracy: 0.4453\\n 3/32 [=>............................] - ETA: 10s - loss: 8.2269 - binary_accuracy: 0.4896\\n 4/32 [==>...........................] - ETA: 10s - loss: 8.7516 - binary_accuracy: 0.4570\\n 5/32 [===>..........................] - ETA: 9s - loss: 8.7642 - binary_accuracy: 0.4562 \\n 6/32 [====>.........................] - ETA: 9s - loss: 8.1850 - binary_accuracy: 0.4922\\n 7/32 [=====>........................] - ETA: 9s - loss: 8.2030 - binary_accuracy: 0.4911\\n 8/32 [======>.......................] - ETA: 8s - loss: 8.2479 - binary_accuracy: 0.4883\\n 9/32 [=======>......................] - ETA: 8s - loss: 8.3109 - binary_accuracy: 0.4844\\n10/32 [========>.....................] - ETA: 8s - loss: 8.3109 - binary_accuracy: 0.4844\\n11/32 [=========>....................] - ETA: 7s - loss: 8.2422 - binary_accuracy: 0.4886\\n12/32 [==========>...................] - ETA: 7s - loss: 8.2269 - binary_accuracy: 0.4896\\n13/32 [===========>..................] - ETA: 6s - loss: 8.0978 - binary_accuracy: 0.4976\\n14/32 [============>.................] - ETA: 6s - loss: 8.0231 - binary_accuracy: 0.5022\\n15/32 [=============>................] - ETA: 6s - loss: 7.9919 - binary_accuracy: 0.5042\\n16/32 [==============>...............] - ETA: 5s - loss: 7.9174 - binary_accuracy: 0.5088\\n17/32 [==============>...............] - ETA: 5s - loss: 7.8665 - binary_accuracy: 0.5119\\n18/32 [===============>..............] - ETA: 5s - loss: 8.0031 - binary_accuracy: 0.5035\\n19/32 [================>.............] - ETA: 4s - loss: 7.9530 - binary_accuracy: 0.5066\\n20/32 [=================>............] - ETA: 4s - loss: 7.8953 - binary_accuracy: 0.5102\\n21/32 [==================>...........] - ETA: 4s - loss: 7.9391 - binary_accuracy: 0.5074\\n22/32 [===================>..........] - ETA: 3s - loss: 7.9560 - binary_accuracy: 0.5064\\n23/32 [====================>.........] - ETA: 3s - loss: 8.0262 - binary_accuracy: 0.5020\\n24/32 [=====================>........] - ETA: 2s - loss: 8.1010 - binary_accuracy: 0.4974\\n25/32 [======================>.......] - ETA: 2s - loss: 8.0993 - binary_accuracy: 0.4975\\n26/32 [=======================>......] - ETA: 2s - loss: 8.1559 - binary_accuracy: 0.4940\\n27/32 [========================>.....] - ETA: 1s - loss: 8.0964 - binary_accuracy: 0.4977\\n28/32 [=========================>....] - ETA: 1s - loss: 8.0231 - binary_accuracy: 0.5022\\n29/32 [==========================>...] - ETA: 1s - loss: 8.0417 - binary_accuracy: 0.5011\\n30/32 [===========================>..] - ETA: 0s - loss: 8.0003 - binary_accuracy: 0.5036\\n31/32 [============================>.] - ETA: 0s - loss: 8.0266 - binary_accuracy: 0.5020\\n32/32 [==============================] - 12s 389ms/step - loss: 7.9882 - binary_accuracy: 0.5044 - val_loss: 7.9331 - val_binary_accuracy: 0.5078\\n\\nEpoch 00003: val_loss improved from 7.99609 to 7.93313, saving model to AC7009C49B32C89DFE03EF7B8D47C53D.h5\\nEpoch 4/500\\n\\n 1/32 [..............................] - ETA: 11s - loss: 7.3035 - binary_accuracy: 0.5469\\n 2/32 [>.............................] - ETA: 11s - loss: 7.9331 - binary_accuracy: 0.5078\\n 3/32 [=>............................] - ETA: 10s - loss: 7.9751 - binary_accuracy: 0.5052\\n 4/32 [==>...........................] - ETA: 10s - loss: 7.9331 - binary_accuracy: 0.5078\\n 5/32 [===>..........................] - ETA: 9s - loss: 8.2605 - binary_accuracy: 0.4875 \\n 6/32 [====>.........................] - ETA: 9s - loss: 8.0590 - binary_accuracy: 0.5000\\n 7/32 [=====>........................] - ETA: 9s - loss: 8.0590 - binary_accuracy: 0.5000\\n 8/32 [======>.......................] - ETA: 8s - loss: 8.0276 - binary_accuracy: 0.5020\\n 9/32 [=======>......................] - ETA: 8s - loss: 8.2269 - binary_accuracy: 0.4896\\n10/32 [========>.....................] - ETA: 8s - loss: 8.0339 - binary_accuracy: 0.5016\\n11/32 [=========>....................] - ETA: 7s - loss: 8.0133 - binary_accuracy: 0.5028\\n12/32 [==========>...................] - ETA: 7s - loss: 8.1010 - binary_accuracy: 0.4974\\n13/32 [===========>..................] - ETA: 7s - loss: 7.9816 - binary_accuracy: 0.5048\\n14/32 [============>.................] - ETA: 6s - loss: 8.0231 - binary_accuracy: 0.5022\\n15/32 [=============>................] - ETA: 6s - loss: 7.9415 - binary_accuracy: 0.5073\\n16/32 [==============>...............] - ETA: 5s - loss: 7.9174 - binary_accuracy: 0.5088\\n17/32 [==============>...............] - ETA: 5s - loss: 7.9405 - binary_accuracy: 0.5074\\n18/32 [===============>..............] - ETA: 5s - loss: 8.0031 - binary_accuracy: 0.5035\\n19/32 [================>.............] - ETA: 4s - loss: 8.0193 - binary_accuracy: 0.5025\\n20/32 [=================>............] - ETA: 4s - loss: 8.0087 - binary_accuracy: 0.5031\\n21/32 [==================>...........] - ETA: 4s - loss: 8.0351 - binary_accuracy: 0.5015\\n22/32 [===================>..........] - ETA: 3s - loss: 8.0590 - binary_accuracy: 0.5000\\n23/32 [====================>.........] - ETA: 3s - loss: 7.9605 - binary_accuracy: 0.5061\\n24/32 [=====================>........] - ETA: 2s - loss: 8.0171 - binary_accuracy: 0.5026\\n25/32 [======================>.......] - ETA: 2s - loss: 8.0288 - binary_accuracy: 0.5019\\n26/32 [=======================>......] - ETA: 2s - loss: 8.0106 - binary_accuracy: 0.5030\\n27/32 [========================>.....] - ETA: 1s - loss: 8.0497 - binary_accuracy: 0.5006\\n28/32 [=========================>....] - ETA: 1s - loss: 8.0141 - binary_accuracy: 0.5028\\n29/32 [==========================>...] - ETA: 1s - loss: 8.0590 - binary_accuracy: 0.5000\\n30/32 [===========================>..] - ETA: 0s - loss: 8.0255 - binary_accuracy: 0.5021\\n31/32 [============================>.] - ETA: 0s - loss: 8.0266 - binary_accuracy: 0.5020\\n32/32 [==============================] - 12s 389ms/step - loss: 8.0118 - binary_accuracy: 0.5029 - val_loss: 8.0590 - val_binary_accuracy: 0.5000\\n\\nEpoch 00004: val_loss did not improve from 7.93313\\nEpoch 5/500\\n\\n 1/32 [..............................] - ETA: 11s - loss: 7.0517 - binary_accuracy: 0.5625\\n 2/32 [>.............................] - ETA: 11s - loss: 7.3035 - binary_accuracy: 0.5469\\n 3/32 [=>............................] - ETA: 10s - loss: 7.1356 - binary_accuracy: 0.5573\\n 4/32 [==>...........................] - ETA: 10s - loss: 7.0517 - binary_accuracy: 0.5625\\n 5/32 [===>..........................] - ETA: 9s - loss: 7.1020 - binary_accuracy: 0.5594 \\n 6/32 [====>.........................] - ETA: 9s - loss: 7.1356 - binary_accuracy: 0.5573\\n 7/32 [=====>........................] - ETA: 9s - loss: 7.4834 - binary_accuracy: 0.5357\\n 8/32 [======>.......................] - ETA: 8s - loss: 7.3980 - binary_accuracy: 0.5410\\n 9/32 [=======>......................] - ETA: 8s - loss: 7.5833 - binary_accuracy: 0.5295\\n10/32 [========>.....................] - ETA: 8s - loss: 7.7316 - binary_accuracy: 0.5203\\n11/32 [=========>....................] - ETA: 7s - loss: 7.7614 - binary_accuracy: 0.5185\\n12/32 [==========>...................] - ETA: 7s - loss: 7.8912 - binary_accuracy: 0.5104\\n13/32 [===========>..................] - ETA: 6s - loss: 7.9428 - binary_accuracy: 0.5072\\n14/32 [============>.................] - ETA: 6s - loss: 7.9871 - binary_accuracy: 0.5045\\n15/32 [=============>................] - ETA: 6s - loss: 7.8912 - binary_accuracy: 0.5104\\n16/32 [==============>...............] - ETA: 5s - loss: 7.9174 - binary_accuracy: 0.5088\\n17/32 [==============>...............] - ETA: 5s - loss: 7.9553 - binary_accuracy: 0.5064\\n18/32 [===============>..............] - ETA: 5s - loss: 7.9471 - binary_accuracy: 0.5069\\n19/32 [================>.............] - ETA: 4s - loss: 7.9398 - binary_accuracy: 0.5074\\n20/32 [=================>............] - ETA: 4s - loss: 7.9583 - binary_accuracy: 0.5062\\n21/32 [==================>...........] - ETA: 4s - loss: 7.9511 - binary_accuracy: 0.5067\\n22/32 [===================>..........] - ETA: 3s - loss: 7.9102 - binary_accuracy: 0.5092\\n23/32 [====================>.........] - ETA: 3s - loss: 7.9714 - binary_accuracy: 0.5054\\n24/32 [=====================>........] - ETA: 2s - loss: 8.0171 - binary_accuracy: 0.5026\\n25/32 [======================>.......] - ETA: 2s - loss: 7.9986 - binary_accuracy: 0.5038\\n26/32 [=======================>......] - ETA: 2s - loss: 7.9719 - binary_accuracy: 0.5054\\n27/32 [========================>.....] - ETA: 1s - loss: 7.9378 - binary_accuracy: 0.5075\\n28/32 [=========================>....] - ETA: 1s - loss: 7.9421 - binary_accuracy: 0.5073\\n29/32 [==========================>...] - ETA: 1s - loss: 7.9722 - binary_accuracy: 0.5054\\n30/32 [===========================>..] - ETA: 0s - loss: 7.9667 - binary_accuracy: 0.5057\\n31/32 [============================>.] - ETA: 0s - loss: 8.0266 - binary_accuracy: 0.5020\\n32/32 [==============================] - 12s 389ms/step - loss: 8.0354 - binary_accuracy: 0.5015 - val_loss: 8.1220 - val_binary_accuracy: 0.4961\\n\\nEpoch 00005: val_loss did not improve from 7.93313\\nEpoch 6/500\\n\\n 1/32 [..............................] - ETA: 11s - loss: 8.3109 - binary_accuracy: 0.4844\\n 2/32 [>.............................] - ETA: 11s - loss: 8.1850 - binary_accuracy: 0.4922\\n 3/32 [=>............................] - ETA: 10s - loss: 8.2269 - binary_accuracy: 0.4896\\n 4/32 [==>...........................] - ETA: 10s - loss: 8.1850 - binary_accuracy: 0.4922\\n 5/32 [===>..........................] - ETA: 10s - loss: 7.9583 - binary_accuracy: 0.5062\\n 6/32 [====>.........................] - ETA: 9s - loss: 8.0590 - binary_accuracy: 0.5000 \\n 7/32 [=====>........................] - ETA: 9s - loss: 7.9871 - binary_accuracy: 0.5045\\n 8/32 [======>.......................] - ETA: 8s - loss: 8.2479 - binary_accuracy: 0.4883\\n 9/32 [=======>......................] - ETA: 8s - loss: 8.0031 - binary_accuracy: 0.5035\\n10/32 [========>.....................] - ETA: 8s - loss: 8.0339 - binary_accuracy: 0.5016\\n11/32 [=========>....................] - ETA: 7s - loss: 7.9446 - binary_accuracy: 0.5071\\n12/32 [==========>...................] - ETA: 7s - loss: 7.8912 - binary_accuracy: 0.5104\\n13/32 [===========>..................] - ETA: 7s - loss: 7.8653 - binary_accuracy: 0.5120\\n14/32 [============>.................] - ETA: 6s - loss: 7.8072 - binary_accuracy: 0.5156\\n15/32 [=============>................] - ETA: 6s - loss: 7.8408 - binary_accuracy: 0.5135\\n16/32 [==============>...............] - ETA: 5s - loss: 7.9961 - binary_accuracy: 0.5039\\n17/32 [==============>...............] - ETA: 5s - loss: 8.0146 - binary_accuracy: 0.5028\\n18/32 [===============>..............] - ETA: 5s - loss: 7.9611 - binary_accuracy: 0.5061\\n19/32 [================>.............] - ETA: 4s - loss: 7.9663 - binary_accuracy: 0.5058\\n20/32 [=================>............] - ETA: 4s - loss: 7.9709 - binary_accuracy: 0.5055\\n21/32 [==================>...........] - ETA: 4s - loss: 8.0830 - binary_accuracy: 0.4985\\n22/32 [===================>..........] - ETA: 3s - loss: 8.1392 - binary_accuracy: 0.4950\\n23/32 [====================>.........] - ETA: 3s - loss: 8.1138 - binary_accuracy: 0.4966\\n24/32 [=====================>........] - ETA: 2s - loss: 8.0486 - binary_accuracy: 0.5007\\n25/32 [======================>.......] - ETA: 2s - loss: 8.0792 - binary_accuracy: 0.4988\\n26/32 [=======================>......] - ETA: 2s - loss: 8.0784 - binary_accuracy: 0.4988\\n27/32 [========================>.....] - ETA: 1s - loss: 8.0777 - binary_accuracy: 0.4988\\n28/32 [=========================>....] - ETA: 1s - loss: 8.0411 - binary_accuracy: 0.5011\\n29/32 [==========================>...] - ETA: 1s - loss: 8.0851 - binary_accuracy: 0.4984\\n30/32 [===========================>..] - ETA: 0s - loss: 8.0590 - binary_accuracy: 0.5000\\n31/32 [============================>.] - ETA: 0s - loss: 8.0428 - binary_accuracy: 0.5010\\n32/32 [==============================] - 12s 390ms/step - loss: 8.0197 - binary_accuracy: 0.5024 - val_loss: 8.0905 - val_binary_accuracy: 0.4980\\n\\nEpoch 00006: val_loss did not improve from 7.93313\\nEpoch 7/500\\n\\n 1/32 [..............................] - ETA: 11s - loss: 6.5480 - binary_accuracy: 0.5938\\n 2/32 [>.............................] - ETA: 11s - loss: 7.4294 - binary_accuracy: 0.5391\\n 3/32 [=>............................] - ETA: 10s - loss: 8.2269 - binary_accuracy: 0.4896\\n 4/32 [==>...........................] - ETA: 10s - loss: 8.1850 - binary_accuracy: 0.4922\\n 5/32 [===>..........................] - ETA: 9s - loss: 8.0590 - binary_accuracy: 0.5000 \\n 6/32 [====>.........................] - ETA: 9s - loss: 7.7233 - binary_accuracy: 0.5208\\n 7/32 [=====>........................] - ETA: 9s - loss: 7.9871 - binary_accuracy: 0.5045\\n 8/32 [======>.......................] - ETA: 8s - loss: 8.2165 - binary_accuracy: 0.4902\\n 9/32 [=======>......................] - ETA: 8s - loss: 8.1990 - binary_accuracy: 0.4913\\n10/32 [========>.....................] - ETA: 8s - loss: 8.4116 - binary_accuracy: 0.4781\\n11/32 [=========>....................] - ETA: 7s - loss: 8.3338 - binary_accuracy: 0.4830\\n12/32 [==========>...................] - ETA: 7s - loss: 8.0800 - binary_accuracy: 0.4987\\n13/32 [===========>..................] - ETA: 6s - loss: 8.0590 - binary_accuracy: 0.5000\\n14/32 [============>.................] - ETA: 6s - loss: 7.9331 - binary_accuracy: 0.5078\\n15/32 [=============>................] - ETA: 6s - loss: 7.8576 - binary_accuracy: 0.5125\\n16/32 [==============>...............] - ETA: 5s - loss: 7.9331 - binary_accuracy: 0.5078\\n17/32 [==============>...............] - ETA: 5s - loss: 7.8961 - binary_accuracy: 0.5101\\n18/32 [===============>..............] - ETA: 5s - loss: 7.8772 - binary_accuracy: 0.5113\\n19/32 [================>.............] - ETA: 4s - loss: 7.8867 - binary_accuracy: 0.5107\\n20/32 [=================>............] - ETA: 4s - loss: 7.8702 - binary_accuracy: 0.5117\\n21/32 [==================>...........] - ETA: 4s - loss: 7.8672 - binary_accuracy: 0.5119\\n22/32 [===================>..........] - ETA: 3s - loss: 7.8072 - binary_accuracy: 0.5156\\n23/32 [====================>.........] - ETA: 3s - loss: 7.8072 - binary_accuracy: 0.5156\\n24/32 [=====================>........] - ETA: 2s - loss: 7.9016 - binary_accuracy: 0.5098\\n25/32 [======================>.......] - ETA: 2s - loss: 7.9079 - binary_accuracy: 0.5094\\n26/32 [=======================>......] - ETA: 2s - loss: 7.8847 - binary_accuracy: 0.5108\\n27/32 [========================>.....] - ETA: 1s - loss: 7.9751 - binary_accuracy: 0.5052\\n28/32 [=========================>....] - ETA: 1s - loss: 7.9331 - binary_accuracy: 0.5078\\n29/32 [==========================>...] - ETA: 1s - loss: 7.9288 - binary_accuracy: 0.5081\\n30/32 [===========================>..] - ETA: 0s - loss: 7.9499 - binary_accuracy: 0.5068\\n31/32 [============================>.] - ETA: 0s - loss: 7.9778 - binary_accuracy: 0.5050\\n32/32 [==============================] - 12s 389ms/step - loss: 8.0197 - binary_accuracy: 0.5024 - val_loss: 8.0905 - val_binary_accuracy: 0.4980\\n\\nEpoch 00007: val_loss did not improve from 7.93313\\nEpoch 8/500\\n\\n 1/32 [..............................] - ETA: 11s - loss: 8.0590 - binary_accuracy: 0.5000\\n 2/32 [>.............................] - ETA: 11s - loss: 8.1850 - binary_accuracy: 0.4922\\n 3/32 [=>............................] - ETA: 10s - loss: 8.1430 - binary_accuracy: 0.4948\\n 4/32 [==>...........................] - ETA: 10s - loss: 7.8702 - binary_accuracy: 0.5117\\n 5/32 [===>..........................] - ETA: 9s - loss: 8.1094 - binary_accuracy: 0.4969 \\n 6/32 [====>.........................] - ETA: 9s - loss: 8.0590 - binary_accuracy: 0.5000\\n 7/32 [=====>........................] - ETA: 9s - loss: 7.9151 - binary_accuracy: 0.5089\\n 8/32 [======>.......................] - ETA: 8s - loss: 7.9646 - binary_accuracy: 0.5059\\n 9/32 [=======>......................] - ETA: 8s - loss: 8.0590 - binary_accuracy: 0.5000\\n10/32 [========>.....................] - ETA: 8s - loss: 8.0842 - binary_accuracy: 0.4984\\n11/32 [=========>....................] - ETA: 7s - loss: 8.1735 - binary_accuracy: 0.4929\\n12/32 [==========>...................] - ETA: 7s - loss: 8.1220 - binary_accuracy: 0.4961\\n13/32 [===========>..................] - ETA: 7s - loss: 8.0978 - binary_accuracy: 0.4976\\n14/32 [============>.................] - ETA: 6s - loss: 8.1310 - binary_accuracy: 0.4955\\n15/32 [=============>................] - ETA: 6s - loss: 8.0758 - binary_accuracy: 0.4990\\n16/32 [==============>...............] - ETA: 5s - loss: 8.0118 - binary_accuracy: 0.5029\\n17/32 [==============>...............] - ETA: 5s - loss: 7.9998 - binary_accuracy: 0.5037\\n18/32 [===============>..............] - ETA: 5s - loss: 7.9471 - binary_accuracy: 0.5069\\n19/32 [================>.............] - ETA: 4s - loss: 7.9795 - binary_accuracy: 0.5049\\n20/32 [=================>............] - ETA: 4s - loss: 8.0465 - binary_accuracy: 0.5008\\n21/32 [==================>...........] - ETA: 4s - loss: 7.9871 - binary_accuracy: 0.5045\\n22/32 [===================>..........] - ETA: 3s - loss: 7.9789 - binary_accuracy: 0.5050\\n23/32 [====================>.........] - ETA: 3s - loss: 7.9167 - binary_accuracy: 0.5088\\n24/32 [=====================>........] - ETA: 2s - loss: 7.9331 - binary_accuracy: 0.5078\\n25/32 [======================>.......] - ETA: 2s - loss: 7.9281 - binary_accuracy: 0.5081\\n26/32 [=======================>......] - ETA: 2s - loss: 7.9234 - binary_accuracy: 0.5084\\n27/32 [========================>.....] - ETA: 1s - loss: 7.9098 - binary_accuracy: 0.5093\\n28/32 [=========================>....] - ETA: 1s - loss: 7.8522 - binary_accuracy: 0.5128\\n29/32 [==========================>...] - ETA: 1s - loss: 7.8506 - binary_accuracy: 0.5129\\n30/32 [===========================>..] - ETA: 0s - loss: 7.8492 - binary_accuracy: 0.5130\\n31/32 [============================>.] - ETA: 0s - loss: 7.8884 - binary_accuracy: 0.5106\\n32/32 [==============================] - 12s 390ms/step - loss: 7.9803 - binary_accuracy: 0.5049 - val_loss: 8.0590 - val_binary_accuracy: 0.5000\\n\\nEpoch 00008: val_loss did not improve from 7.93313\\nEpoch 9/500\\n\\n 1/32 [..............................] - ETA: 11s - loss: 7.0517 - binary_accuracy: 0.5625\\n 2/32 [>.............................] - ETA: 11s - loss: 7.1776 - binary_accuracy: 0.5547\\n 3/32 [=>............................] - ETA: 10s - loss: 7.7233 - binary_accuracy: 0.5208\\n 4/32 [==>...........................] - ETA: 10s - loss: 7.8072 - binary_accuracy: 0.5156\\n 5/32 [===>..........................] - ETA: 9s - loss: 7.7568 - binary_accuracy: 0.5188 \\n 6/32 [====>.........................] - ETA: 9s - loss: 7.8912 - binary_accuracy: 0.5104\\n 7/32 [=====>........................] - ETA: 9s - loss: 8.0590 - binary_accuracy: 0.5000\\n 8/32 [======>.......................] - ETA: 8s - loss: 8.0590 - binary_accuracy: 0.5000\\n 9/32 [=======>......................] - ETA: 8s - loss: 8.0870 - binary_accuracy: 0.4983\\n10/32 [========>.....................] - ETA: 8s - loss: 8.1094 - binary_accuracy: 0.4969\\n11/32 [=========>....................] - ETA: 7s - loss: 7.9675 - binary_accuracy: 0.5057\\n12/32 [==========>...................] - ETA: 7s - loss: 8.0381 - binary_accuracy: 0.5013\\n13/32 [===========>..................] - ETA: 7s - loss: 8.0009 - binary_accuracy: 0.5036\\n14/32 [============>.................] - ETA: 6s - loss: 8.0051 - binary_accuracy: 0.5033\\n15/32 [=============>................] - ETA: 6s - loss: 7.9919 - binary_accuracy: 0.5042\\n16/32 [==============>...............] - ETA: 5s - loss: 8.0433 - binary_accuracy: 0.5010\\n17/32 [==============>...............] - ETA: 5s - loss: 8.0887 - binary_accuracy: 0.4982\\n18/32 [===============>..............] - ETA: 5s - loss: 8.0171 - binary_accuracy: 0.5026\\n19/32 [================>.............] - ETA: 4s - loss: 7.9663 - binary_accuracy: 0.5058\\n20/32 [=================>............] - ETA: 4s - loss: 7.8576 - binary_accuracy: 0.5125\\n21/32 [==================>...........] - ETA: 4s - loss: 7.8912 - binary_accuracy: 0.5104\\n22/32 [===================>..........] - ETA: 3s - loss: 7.9446 - binary_accuracy: 0.5071\\n23/32 [====================>.........] - ETA: 3s - loss: 7.9605 - binary_accuracy: 0.5061\\n24/32 [=====================>........] - ETA: 2s - loss: 7.9541 - binary_accuracy: 0.5065\\n25/32 [======================>.......] - ETA: 2s - loss: 8.0188 - binary_accuracy: 0.5025\\n26/32 [=======================>......] - ETA: 2s - loss: 8.0784 - binary_accuracy: 0.4988\\n27/32 [========================>.....] - ETA: 1s - loss: 8.0964 - binary_accuracy: 0.4977\\n28/32 [=========================>....] - ETA: 1s - loss: 8.0950 - binary_accuracy: 0.4978\\n29/32 [==========================>...] - ETA: 1s - loss: 8.1025 - binary_accuracy: 0.4973\\n30/32 [===========================>..] - ETA: 0s - loss: 8.1094 - binary_accuracy: 0.4969\\n31/32 [============================>.] - ETA: 0s - loss: 8.0753 - binary_accuracy: 0.4990\\n32/32 [==============================] - 12s 390ms/step - loss: 8.0590 - binary_accuracy: 0.5000 - val_loss: 8.0276 - val_binary_accuracy: 0.5020\\n\\nEpoch 00009: val_loss did not improve from 7.93313\\nEpoch 10/500\\n\\n 1/32 [..............................] - ETA: 11s - loss: 8.0590 - binary_accuracy: 0.5000\\n 2/32 [>.............................] - ETA: 11s - loss: 9.3183 - binary_accuracy: 0.4219\\n 3/32 [=>............................] - ETA: 10s - loss: 8.8985 - binary_accuracy: 0.4479\\n 4/32 [==>...........................] - ETA: 10s - loss: 8.8146 - binary_accuracy: 0.4531\\n 5/32 [===>..........................] - ETA: 9s - loss: 8.7138 - binary_accuracy: 0.4594 \\n 6/32 [====>.........................] - ETA: 9s - loss: 8.4368 - binary_accuracy: 0.4766\\n 7/32 [=====>........................] - ETA: 9s - loss: 8.4188 - binary_accuracy: 0.4777\\n 8/32 [======>.......................] - ETA: 8s - loss: 8.3739 - binary_accuracy: 0.4805\\n 9/32 [=======>......................] - ETA: 8s - loss: 8.1430 - binary_accuracy: 0.4948\\n10/32 [========>.....................] - ETA: 8s - loss: 8.0590 - binary_accuracy: 0.5000\\n11/32 [=========>....................] - ETA: 7s - loss: 8.0819 - binary_accuracy: 0.4986\\n12/32 [==========>...................] - ETA: 7s - loss: 8.1430 - binary_accuracy: 0.4948\\n13/32 [===========>..................] - ETA: 7s - loss: 8.2528 - binary_accuracy: 0.4880\\n14/32 [============>.................] - ETA: 6s - loss: 8.3469 - binary_accuracy: 0.4821\\n15/32 [=============>................] - ETA: 6s - loss: 8.3277 - binary_accuracy: 0.4833\\n16/32 [==============>...............] - ETA: 5s - loss: 8.2952 - binary_accuracy: 0.4854\\n17/32 [==============>...............] - ETA: 5s - loss: 8.3257 - binary_accuracy: 0.4835\\n18/32 [===============>..............] - ETA: 5s - loss: 8.2409 - binary_accuracy: 0.4887\\n19/32 [================>.............] - ETA: 4s - loss: 8.1651 - binary_accuracy: 0.4934\\n20/32 [=================>............] - ETA: 4s - loss: 8.1724 - binary_accuracy: 0.4930\\n21/32 [==================>...........] - ETA: 4s - loss: 8.1790 - binary_accuracy: 0.4926\\n22/32 [===================>..........] - ETA: 3s - loss: 8.1392 - binary_accuracy: 0.4950\\n23/32 [====================>.........] - ETA: 3s - loss: 8.0809 - binary_accuracy: 0.4986\\n24/32 [=====================>........] - ETA: 2s - loss: 8.1010 - binary_accuracy: 0.4974\\n25/32 [======================>.......] - ETA: 2s - loss: 8.0590 - binary_accuracy: 0.5000\\n26/32 [=======================>......] - ETA: 2s - loss: 8.0300 - binary_accuracy: 0.5018\\n27/32 [========================>.....] - ETA: 1s - loss: 7.9938 - binary_accuracy: 0.5041\\n28/32 [=========================>....] - ETA: 1s - loss: 8.0501 - binary_accuracy: 0.5006\\n29/32 [==========================>...] - ETA: 1s - loss: 8.1112 - binary_accuracy: 0.4968\\n30/32 [===========================>..] - ETA: 0s - loss: 8.0758 - binary_accuracy: 0.4990\\n31/32 [============================>.] - ETA: 0s - loss: 8.0428 - binary_accuracy: 0.5010\\n32/32 [==============================] - 12s 389ms/step - loss: 8.0433 - binary_accuracy: 0.5010 - val_loss: 7.9961 - val_binary_accuracy: 0.5039\\n\\nEpoch 00010: val_loss did not improve from 7.93313\\nEpoch 11/500\\n\\n 1/32 [..............................] - ETA: 11s - loss: 9.3183 - binary_accuracy: 0.4219\\n 2/32 [>.............................] - ETA: 11s - loss: 8.0590 - binary_accuracy: 0.5000\\n 3/32 [=>............................] - ETA: 10s - loss: 8.8985 - binary_accuracy: 0.4479\\n 4/32 [==>...........................] - ETA: 10s - loss: 8.1220 - binary_accuracy: 0.4961\\n 5/32 [===>..........................] - ETA: 9s - loss: 8.0590 - binary_accuracy: 0.5000 \\n 6/32 [====>.........................] - ETA: 9s - loss: 7.8492 - binary_accuracy: 0.5130\\n 7/32 [=====>........................] - ETA: 9s - loss: 8.0590 - binary_accuracy: 0.5000\\n 8/32 [======>.......................] - ETA: 8s - loss: 7.9016 - binary_accuracy: 0.5098\\n 9/32 [=======>......................] - ETA: 8s - loss: 7.9471 - binary_accuracy: 0.5069\\n10/32 [========>.....................] - ETA: 8s - loss: 8.0590 - binary_accuracy: 0.5000\\n11/32 [=========>....................] - ETA: 7s - loss: 8.2193 - binary_accuracy: 0.4901\\n12/32 [==========>...................] - ETA: 7s - loss: 8.1430 - binary_accuracy: 0.4948\\n13/32 [===========>..................] - ETA: 7s - loss: 8.1947 - binary_accuracy: 0.4916\\n14/32 [============>.................] - ETA: 6s - loss: 8.0590 - binary_accuracy: 0.5000\\n15/32 [=============>................] - ETA: 6s - loss: 8.0758 - binary_accuracy: 0.4990\\n16/32 [==============>...............] - ETA: 5s - loss: 8.1063 - binary_accuracy: 0.4971\\n17/32 [==============>...............] - ETA: 5s - loss: 8.1776 - binary_accuracy: 0.4926\\n18/32 [===============>..............] - ETA: 5s - loss: 8.1990 - binary_accuracy: 0.4913\\n19/32 [================>.............] - ETA: 4s - loss: 8.1916 - binary_accuracy: 0.4918\\n20/32 [=================>............] - ETA: 4s - loss: 8.1094 - binary_accuracy: 0.4969\\n21/32 [==================>...........] - ETA: 4s - loss: 8.1550 - binary_accuracy: 0.4940\\n22/32 [===================>..........] - ETA: 3s - loss: 8.2193 - binary_accuracy: 0.4901\\n23/32 [====================>.........] - ETA: 3s - loss: 8.2561 - binary_accuracy: 0.4878\\n24/32 [=====================>........] - ETA: 2s - loss: 8.2269 - binary_accuracy: 0.4896\\n25/32 [======================>.......] - ETA: 2s - loss: 8.2202 - binary_accuracy: 0.4900\\n26/32 [=======================>......] - ETA: 2s - loss: 8.1947 - binary_accuracy: 0.4916\\n27/32 [========================>.....] - ETA: 1s - loss: 8.1803 - binary_accuracy: 0.4925\\n28/32 [=========================>....] - ETA: 1s - loss: 8.2209 - binary_accuracy: 0.4900\\n29/32 [==========================>...] - ETA: 1s - loss: 8.2154 - binary_accuracy: 0.4903\\n30/32 [===========================>..] - ETA: 0s - loss: 8.1598 - binary_accuracy: 0.4938\\n31/32 [============================>.] - ETA: 0s - loss: 8.1322 - binary_accuracy: 0.4955\\n32/32 [==============================] - 12s 389ms/step - loss: 8.0590 - binary_accuracy: 0.5000 - val_loss: 8.0276 - val_binary_accuracy: 0.5020\\n\\nEpoch 00011: val_loss did not improve from 7.93313\\nEpoch 12/500\\n\\n 1/32 [..............................] - ETA: 11s - loss: 7.0517 - binary_accuracy: 0.5625\\n 2/32 [>.............................] - ETA: 11s - loss: 7.9331 - binary_accuracy: 0.5078\\n 3/32 [=>............................] - ETA: 10s - loss: 7.8912 - binary_accuracy: 0.5104\\n 4/32 [==>...........................] - ETA: 10s - loss: 8.0590 - binary_accuracy: 0.5000\\n 5/32 [===>..........................] - ETA: 9s - loss: 8.2102 - binary_accuracy: 0.4906 \\n 6/32 [====>.........................] - ETA: 9s - loss: 8.1850 - binary_accuracy: 0.4922\\n 7/32 [=====>........................] - ETA: 9s - loss: 8.2389 - binary_accuracy: 0.4888\\n 8/32 [======>.......................] - ETA: 8s - loss: 8.2165 - binary_accuracy: 0.4902\\n 9/32 [=======>......................] - ETA: 8s - loss: 8.0031 - binary_accuracy: 0.5035\\n10/32 [========>.....................] - ETA: 8s - loss: 7.7820 - binary_accuracy: 0.5172\\n11/32 [=========>....................] - ETA: 7s - loss: 7.6698 - binary_accuracy: 0.5241\\n12/32 [==========>...................] - ETA: 7s - loss: 7.7233 - binary_accuracy: 0.5208\\n13/32 [===========>..................] - ETA: 7s - loss: 7.7685 - binary_accuracy: 0.5180\\n14/32 [============>.................] - ETA: 6s - loss: 7.9151 - binary_accuracy: 0.5089\\n15/32 [=============>................] - ETA: 6s - loss: 7.9919 - binary_accuracy: 0.5042\\n16/32 [==============>...............] - ETA: 5s - loss: 8.0118 - binary_accuracy: 0.5029\\n17/32 [==============>...............] - ETA: 5s - loss: 8.0442 - binary_accuracy: 0.5009\\n18/32 [===============>..............] - ETA: 5s - loss: 8.0730 - binary_accuracy: 0.4991\\n19/32 [================>.............] - ETA: 4s - loss: 8.0988 - binary_accuracy: 0.4975\\n20/32 [=================>............] - ETA: 4s - loss: 8.1976 - binary_accuracy: 0.4914\\n21/32 [==================>...........] - ETA: 4s - loss: 8.1670 - binary_accuracy: 0.4933\\n22/32 [===================>..........] - ETA: 3s - loss: 8.0476 - binary_accuracy: 0.5007\\n23/32 [====================>.........] - ETA: 3s - loss: 7.9933 - binary_accuracy: 0.5041\\n24/32 [=====================>........] - ETA: 2s - loss: 8.0381 - binary_accuracy: 0.5013\\n25/32 [======================>.......] - ETA: 2s - loss: 8.0087 - binary_accuracy: 0.5031\\n26/32 [=======================>......] - ETA: 2s - loss: 8.0009 - binary_accuracy: 0.5036\\n27/32 [========================>.....] - ETA: 1s - loss: 8.0217 - binary_accuracy: 0.5023\\n28/32 [=========================>....] - ETA: 1s - loss: 7.9421 - binary_accuracy: 0.5073\\n29/32 [==========================>...] - ETA: 1s - loss: 7.9548 - binary_accuracy: 0.5065\\n30/32 [===========================>..] - ETA: 0s - loss: 7.9751 - binary_accuracy: 0.5052\\n31/32 [============================>.] - ETA: 0s - loss: 7.9616 - binary_accuracy: 0.5060\\n32/32 [==============================] - 12s 390ms/step - loss: 8.0433 - binary_accuracy: 0.5010 - val_loss: 8.0590 - val_binary_accuracy: 0.5000\\n\\nEpoch 00012: val_loss did not improve from 7.93313\\nEpoch 13/500\\n\\n 1/32 [..............................] - ETA: 11s - loss: 8.3109 - binary_accuracy: 0.4844\\n 2/32 [>.............................] - ETA: 11s - loss: 7.3035 - binary_accuracy: 0.5469\\n 3/32 [=>............................] - ETA: 10s - loss: 7.1356 - binary_accuracy: 0.5573\\n 4/32 [==>...........................] - ETA: 10s - loss: 7.1776 - binary_accuracy: 0.5547\\n 5/32 [===>..........................] - ETA: 9s - loss: 7.5554 - binary_accuracy: 0.5312 \\n 6/32 [====>.........................] - ETA: 9s - loss: 7.5554 - binary_accuracy: 0.5312\\n 7/32 [=====>........................] - ETA: 9s - loss: 7.7712 - binary_accuracy: 0.5179\\n 8/32 [======>.......................] - ETA: 8s - loss: 7.9331 - binary_accuracy: 0.5078\\n 9/32 [=======>......................] - ETA: 8s - loss: 8.0590 - binary_accuracy: 0.5000\\n10/32 [========>.....................] - ETA: 8s - loss: 7.9835 - binary_accuracy: 0.5047\\n11/32 [=========>....................] - ETA: 7s - loss: 8.0133 - binary_accuracy: 0.5028\\n12/32 [==========>...................] - ETA: 7s - loss: 8.1010 - binary_accuracy: 0.4974\\n13/32 [===========>..................] - ETA: 7s - loss: 8.1753 - binary_accuracy: 0.4928\\n14/32 [============>.................] - ETA: 6s - loss: 8.1670 - binary_accuracy: 0.4933\\n15/32 [=============>................] - ETA: 6s - loss: 8.2605 - binary_accuracy: 0.4875\\n16/32 [==============>...............] - ETA: 5s - loss: 8.2007 - binary_accuracy: 0.4912\\n17/32 [==============>...............] - ETA: 5s - loss: 8.2368 - binary_accuracy: 0.4890\\n18/32 [===============>..............] - ETA: 5s - loss: 8.1990 - binary_accuracy: 0.4913\\n19/32 [================>.............] - ETA: 4s - loss: 8.1783 - binary_accuracy: 0.4926\\n20/32 [=================>............] - ETA: 4s - loss: 8.1346 - binary_accuracy: 0.4953\\n21/32 [==================>...........] - ETA: 4s - loss: 8.1310 - binary_accuracy: 0.4955\\n22/32 [===================>..........] - ETA: 3s - loss: 8.2308 - binary_accuracy: 0.4893\\n23/32 [====================>.........] - ETA: 3s - loss: 8.1685 - binary_accuracy: 0.4932\\n24/32 [=====================>........] - ETA: 2s - loss: 8.2479 - binary_accuracy: 0.4883\\n25/32 [======================>.......] - ETA: 2s - loss: 8.2202 - binary_accuracy: 0.4900\\n26/32 [=======================>......] - ETA: 2s - loss: 8.1365 - binary_accuracy: 0.4952\\n27/32 [========================>.....] - ETA: 1s - loss: 8.1337 - binary_accuracy: 0.4954\\n28/32 [=========================>....] - ETA: 1s - loss: 8.1130 - binary_accuracy: 0.4967\\n29/32 [==========================>...] - ETA: 1s - loss: 8.0938 - binary_accuracy: 0.4978\\n30/32 [===========================>..] - ETA: 0s - loss: 8.1094 - binary_accuracy: 0.4969\\n31/32 [============================>.] - ETA: 0s - loss: 8.0590 - binary_accuracy: 0.5000\\n32/32 [==============================] - 12s 390ms/step - loss: 8.0040 - binary_accuracy: 0.5034 - val_loss: 7.9961 - val_binary_accuracy: 0.5039\\n\\nEpoch 00013: val_loss did not improve from 7.93313\\nEpoch 14/500\\n\\n 1/32 [..............................] - ETA: 11s - loss: 7.0517 - binary_accuracy: 0.5625\\n 2/32 [>.............................] - ETA: 11s - loss: 7.1776 - binary_accuracy: 0.5547\\n 3/32 [=>............................] - ETA: 10s - loss: 7.7233 - binary_accuracy: 0.5208\\n 4/32 [==>...........................] - ETA: 10s - loss: 7.8072 - binary_accuracy: 0.5156\\n 5/32 [===>..........................] - ETA: 9s - loss: 7.7568 - binary_accuracy: 0.5188 \\n 6/32 [====>.........................] - ETA: 9s - loss: 7.7233 - binary_accuracy: 0.5208\\n 7/32 [=====>........................] - ETA: 9s - loss: 7.5554 - binary_accuracy: 0.5312\\n 8/32 [======>.......................] - ETA: 8s - loss: 7.4924 - binary_accuracy: 0.5352\\n 9/32 [=======>......................] - ETA: 8s - loss: 7.5833 - binary_accuracy: 0.5295\\n10/32 [========>.....................] - ETA: 8s - loss: 7.6057 - binary_accuracy: 0.5281\\n11/32 [=========>....................] - ETA: 7s - loss: 7.6927 - binary_accuracy: 0.5227\\n12/32 [==========>...................] - ETA: 7s - loss: 7.8072 - binary_accuracy: 0.5156\\n13/32 [===========>..................] - ETA: 7s - loss: 7.7878 - binary_accuracy: 0.5168\\n14/32 [============>.................] - ETA: 6s - loss: 7.8072 - binary_accuracy: 0.5156\\n15/32 [=============>................] - ETA: 6s - loss: 7.8576 - binary_accuracy: 0.5125\\n16/32 [==============>...............] - ETA: 5s - loss: 7.7915 - binary_accuracy: 0.5166\\n17/32 [==============>...............] - ETA: 5s - loss: 7.8368 - binary_accuracy: 0.5138\\n18/32 [===============>..............] - ETA: 5s - loss: 7.8912 - binary_accuracy: 0.5104\\n19/32 [================>.............] - ETA: 4s - loss: 7.8735 - binary_accuracy: 0.5115\\n20/32 [=================>............] - ETA: 4s - loss: 7.8702 - binary_accuracy: 0.5117\\n21/32 [==================>...........] - ETA: 4s - loss: 7.8552 - binary_accuracy: 0.5126\\n22/32 [===================>..........] - ETA: 3s - loss: 7.8644 - binary_accuracy: 0.5121\\n23/32 [====================>.........] - ETA: 3s - loss: 7.9386 - binary_accuracy: 0.5075\\n24/32 [=====================>........] - ETA: 2s - loss: 7.9541 - binary_accuracy: 0.5065\\n25/32 [======================>.......] - ETA: 2s - loss: 7.9684 - binary_accuracy: 0.5056\\n26/32 [=======================>......] - ETA: 2s - loss: 7.9816 - binary_accuracy: 0.5048\\n27/32 [========================>.....] - ETA: 1s - loss: 8.0031 - binary_accuracy: 0.5035\\n28/32 [=========================>....] - ETA: 1s - loss: 8.0051 - binary_accuracy: 0.5033\\n29/32 [==========================>...] - ETA: 1s - loss: 7.9896 - binary_accuracy: 0.5043\\n30/32 [===========================>..] - ETA: 0s - loss: 8.0339 - binary_accuracy: 0.5016\\n31/32 [============================>.] - ETA: 0s - loss: 7.9941 - binary_accuracy: 0.5040\\n32/32 [==============================] - 12s 390ms/step - loss: 7.9961 - binary_accuracy: 0.5039 - val_loss: 8.1220 - val_binary_accuracy: 0.4961\\n\\nEpoch 00014: val_loss did not improve from 7.93313\\nEpoch 15/500\\n\\n 1/32 [..............................] - ETA: 11s - loss: 7.0517 - binary_accuracy: 0.5625\\n 2/32 [>.............................] - ETA: 11s - loss: 7.8072 - binary_accuracy: 0.5156\\n 3/32 [=>............................] - ETA: 10s - loss: 7.3875 - binary_accuracy: 0.5417\\n 4/32 [==>...........................] - ETA: 10s - loss: 7.4924 - binary_accuracy: 0.5352\\n 5/32 [===>..........................] - ETA: 10s - loss: 7.1524 - binary_accuracy: 0.5563\\n 6/32 [====>.........................] - ETA: 9s - loss: 7.4294 - binary_accuracy: 0.5391 \\n 7/32 [=====>........................] - ETA: 9s - loss: 7.5554 - binary_accuracy: 0.5312\\n 8/32 [======>.......................] - ETA: 8s - loss: 7.7757 - binary_accuracy: 0.5176\\n 9/32 [=======>......................] - ETA: 8s - loss: 7.7512 - binary_accuracy: 0.5191\\n10/32 [========>.....................] - ETA: 8s - loss: 7.6561 - binary_accuracy: 0.5250\\n11/32 [=========>....................] - ETA: 7s - loss: 7.9217 - binary_accuracy: 0.5085\\n12/32 [==========>...................] - ETA: 7s - loss: 7.8492 - binary_accuracy: 0.5130\\n13/32 [===========>..................] - ETA: 7s - loss: 7.8266 - binary_accuracy: 0.5144\\n14/32 [============>.................] - ETA: 6s - loss: 7.7173 - binary_accuracy: 0.5212\\n15/32 [=============>................] - ETA: 6s - loss: 7.7233 - binary_accuracy: 0.5208\\n16/32 [==============>...............] - ETA: 5s - loss: 7.7442 - binary_accuracy: 0.5195\\n17/32 [==============>...............] - ETA: 5s - loss: 7.8516 - binary_accuracy: 0.5129\\n18/32 [===============>..............] - ETA: 5s - loss: 7.7792 - binary_accuracy: 0.5174\\n19/32 [================>.............] - ETA: 4s - loss: 7.7807 - binary_accuracy: 0.5173\\n20/32 [=================>............] - ETA: 4s - loss: 7.8450 - binary_accuracy: 0.5133\\n21/32 [==================>...........] - ETA: 4s - loss: 7.8552 - binary_accuracy: 0.5126\\n22/32 [===================>..........] - ETA: 3s - loss: 7.8530 - binary_accuracy: 0.5128\\n23/32 [====================>.........] - ETA: 3s - loss: 7.9167 - binary_accuracy: 0.5088\\n24/32 [=====================>........] - ETA: 2s - loss: 7.9121 - binary_accuracy: 0.5091\\n25/32 [======================>.......] - ETA: 2s - loss: 7.9281 - binary_accuracy: 0.5081\\n26/32 [=======================>......] - ETA: 2s - loss: 7.8944 - binary_accuracy: 0.5102\\n27/32 [========================>.....] - ETA: 1s - loss: 7.9098 - binary_accuracy: 0.5093\\n28/32 [=========================>....] - ETA: 1s - loss: 7.9151 - binary_accuracy: 0.5089\\n29/32 [==========================>...] - ETA: 1s - loss: 7.9288 - binary_accuracy: 0.5081\\n30/32 [===========================>..] - ETA: 0s - loss: 7.9667 - binary_accuracy: 0.5057\\n31/32 [============================>.] - ETA: 0s - loss: 7.9941 - binary_accuracy: 0.5040\\n32/32 [==============================] - 12s 390ms/step - loss: 8.0118 - binary_accuracy: 0.5029 - val_loss: 8.0276 - val_binary_accuracy: 0.5020\\n\\nEpoch 00015: val_loss did not improve from 7.93313\\nEpoch 16/500\\n\\n 1/32 [..............................] - ETA: 11s - loss: 8.5627 - binary_accuracy: 0.4688\\n 2/32 [>.............................] - ETA: 11s - loss: 8.6887 - binary_accuracy: 0.4609\\n 3/32 [=>............................] - ETA: 10s - loss: 8.1430 - binary_accuracy: 0.4948\\n 4/32 [==>...........................] - ETA: 10s - loss: 8.3739 - binary_accuracy: 0.4805\\n 5/32 [===>..........................] - ETA: 9s - loss: 8.4620 - binary_accuracy: 0.4750 \\n 6/32 [====>.........................] - ETA: 9s - loss: 8.2269 - binary_accuracy: 0.4896\\n 7/32 [=====>........................] - ETA: 9s - loss: 7.9871 - binary_accuracy: 0.5045\\n 8/32 [======>.......................] - ETA: 8s - loss: 8.0276 - binary_accuracy: 0.5020\\n 9/32 [=======>......................] - ETA: 8s - loss: 7.8632 - binary_accuracy: 0.5122\\n10/32 [========>.....................] - ETA: 8s - loss: 7.8324 - binary_accuracy: 0.5141\\n11/32 [=========>....................] - ETA: 7s - loss: 7.9217 - binary_accuracy: 0.5085\\n12/32 [==========>...................] - ETA: 7s - loss: 8.0800 - binary_accuracy: 0.4987\\n13/32 [===========>..................] - ETA: 6s - loss: 7.9622 - binary_accuracy: 0.5060\\n14/32 [============>.................] - ETA: 6s - loss: 8.0231 - binary_accuracy: 0.5022\\n15/32 [=============>................] - ETA: 6s - loss: 7.9415 - binary_accuracy: 0.5073\\n16/32 [==============>...............] - ETA: 5s - loss: 8.0276 - binary_accuracy: 0.5020\\n17/32 [==============>...............] - ETA: 5s - loss: 8.0146 - binary_accuracy: 0.5028\\n18/32 [===============>..............] - ETA: 5s - loss: 8.0171 - binary_accuracy: 0.5026\\n19/32 [================>.............] - ETA: 4s - loss: 8.0988 - binary_accuracy: 0.4975\\n20/32 [=================>............] - ETA: 4s - loss: 8.1094 - binary_accuracy: 0.4969\\n21/32 [==================>...........] - ETA: 4s - loss: 8.1070 - binary_accuracy: 0.4970\\n22/32 [===================>..........] - ETA: 3s - loss: 8.0590 - binary_accuracy: 0.5000\\n23/32 [====================>.........] - ETA: 3s - loss: 8.0371 - binary_accuracy: 0.5014\\n24/32 [=====================>........] - ETA: 2s - loss: 8.0276 - binary_accuracy: 0.5020\\n25/32 [======================>.......] - ETA: 2s - loss: 8.0490 - binary_accuracy: 0.5006\\n26/32 [=======================>......] - ETA: 2s - loss: 8.0687 - binary_accuracy: 0.4994\\n27/32 [========================>.....] - ETA: 1s - loss: 8.0311 - binary_accuracy: 0.5017\\n28/32 [=========================>....] - ETA: 1s - loss: 8.0770 - binary_accuracy: 0.4989\\n29/32 [==========================>...] - ETA: 1s - loss: 8.0851 - binary_accuracy: 0.4984\\n30/32 [===========================>..] - ETA: 0s - loss: 8.0255 - binary_accuracy: 0.5021\\n31/32 [============================>.] - ETA: 0s - loss: 8.0022 - binary_accuracy: 0.5035\\n32/32 [==============================] - 12s 389ms/step - loss: 8.0118 - binary_accuracy: 0.5029 - val_loss: 8.0276 - val_binary_accuracy: 0.5020\\n\\nEpoch 00016: val_loss did not improve from 7.93313\\nEpoch 17/500\\n\\n 1/32 [..............................] - ETA: 11s - loss: 7.5554 - binary_accuracy: 0.5312\\n 2/32 [>.............................] - ETA: 11s - loss: 8.0590 - binary_accuracy: 0.5000\\n 3/32 [=>............................] - ETA: 10s - loss: 7.9751 - binary_accuracy: 0.5052\\n 4/32 [==>...........................] - ETA: 10s - loss: 8.4998 - binary_accuracy: 0.4727\\n 5/32 [===>..........................] - ETA: 9s - loss: 8.3613 - binary_accuracy: 0.4813 \\n 6/32 [====>.........................] - ETA: 9s - loss: 8.2689 - binary_accuracy: 0.4870\\n 7/32 [=====>........................] - ETA: 9s - loss: 8.3109 - binary_accuracy: 0.4844\\n 8/32 [======>.......................] - ETA: 8s - loss: 8.1850 - binary_accuracy: 0.4922\\n 9/32 [=======>......................] - ETA: 8s - loss: 8.0590 - binary_accuracy: 0.5000\\n10/32 [========>.....................] - ETA: 8s - loss: 7.9835 - binary_accuracy: 0.5047\\n11/32 [=========>....................] - ETA: 7s - loss: 7.8072 - binary_accuracy: 0.5156\\n12/32 [==========>...................] - ETA: 7s - loss: 7.7862 - binary_accuracy: 0.5169\\n13/32 [===========>..................] - ETA: 7s - loss: 7.9234 - binary_accuracy: 0.5084\\n14/32 [============>.................] - ETA: 6s - loss: 7.9511 - binary_accuracy: 0.5067\\n15/32 [=============>................] - ETA: 6s - loss: 7.8912 - binary_accuracy: 0.5104\\n16/32 [==============>...............] - ETA: 5s - loss: 7.8702 - binary_accuracy: 0.5117\\n17/32 [==============>...............] - ETA: 5s - loss: 7.8220 - binary_accuracy: 0.5147\\n18/32 [===============>..............] - ETA: 5s - loss: 7.7372 - binary_accuracy: 0.5200\\n19/32 [================>.............] - ETA: 4s - loss: 7.6614 - binary_accuracy: 0.5247\\n20/32 [=================>............] - ETA: 4s - loss: 7.6561 - binary_accuracy: 0.5250\\n21/32 [==================>...........] - ETA: 4s - loss: 7.7113 - binary_accuracy: 0.5216\\n22/32 [===================>..........] - ETA: 3s - loss: 7.8301 - binary_accuracy: 0.5142\\n23/32 [====================>.........] - ETA: 3s - loss: 7.8839 - binary_accuracy: 0.5109\\n24/32 [=====================>........] - ETA: 2s - loss: 7.8492 - binary_accuracy: 0.5130\\n25/32 [======================>.......] - ETA: 2s - loss: 7.8878 - binary_accuracy: 0.5106\\n26/32 [=======================>......] - ETA: 2s - loss: 7.8653 - binary_accuracy: 0.5120\\n27/32 [========================>.....] - ETA: 1s - loss: 7.8445 - binary_accuracy: 0.5133\\n28/32 [=========================>....] - ETA: 1s - loss: 7.9061 - binary_accuracy: 0.5095\\n29/32 [==========================>...] - ETA: 1s - loss: 7.9462 - binary_accuracy: 0.5070\\n30/32 [===========================>..] - ETA: 0s - loss: 7.9583 - binary_accuracy: 0.5062\\n31/32 [============================>.] - ETA: 0s - loss: 8.0266 - binary_accuracy: 0.5020\\n32/32 [==============================] - 12s 390ms/step - loss: 8.0590 - binary_accuracy: 0.5000 - val_loss: 7.9331 - val_binary_accuracy: 0.5078\\n\\nEpoch 00017: val_loss did not improve from 7.93313\\nEpoch 18/500\\n\\n 1/32 [..............................] - ETA: 11s - loss: 9.0664 - binary_accuracy: 0.4375\\n 2/32 [>.............................] - ETA: 11s - loss: 9.1924 - binary_accuracy: 0.4297\\n 3/32 [=>............................] - ETA: 10s - loss: 9.2343 - binary_accuracy: 0.4271\\n 4/32 [==>...........................] - ETA: 10s - loss: 9.1924 - binary_accuracy: 0.4297\\n 5/32 [===>..........................] - ETA: 9s - loss: 8.9657 - binary_accuracy: 0.4437 \\n 6/32 [====>.........................] - ETA: 9s - loss: 8.7726 - binary_accuracy: 0.4557\\n 7/32 [=====>........................] - ETA: 9s - loss: 8.7786 - binary_accuracy: 0.4554\\n 8/32 [======>.......................] - ETA: 8s - loss: 8.5627 - binary_accuracy: 0.4688\\n 9/32 [=======>......................] - ETA: 8s - loss: 8.7306 - binary_accuracy: 0.4583\\n10/32 [========>.....................] - ETA: 8s - loss: 8.6383 - binary_accuracy: 0.4641\\n11/32 [=========>....................] - ETA: 7s - loss: 8.3796 - binary_accuracy: 0.4801\\n12/32 [==========>...................] - ETA: 7s - loss: 8.2689 - binary_accuracy: 0.4870\\n13/32 [===========>..................] - ETA: 7s - loss: 8.2334 - binary_accuracy: 0.4892\\n14/32 [============>.................] - ETA: 6s - loss: 8.1670 - binary_accuracy: 0.4933\\n15/32 [=============>................] - ETA: 6s - loss: 8.1430 - binary_accuracy: 0.4948\\n16/32 [==============>...............] - ETA: 5s - loss: 8.1377 - binary_accuracy: 0.4951\\n17/32 [==============>...............] - ETA: 5s - loss: 8.1183 - binary_accuracy: 0.4963\\n18/32 [===============>..............] - ETA: 5s - loss: 8.1430 - binary_accuracy: 0.4948\\n19/32 [================>.............] - ETA: 4s - loss: 8.2844 - binary_accuracy: 0.4860\\n20/32 [=================>............] - ETA: 4s - loss: 8.1976 - binary_accuracy: 0.4914\\n21/32 [==================>...........] - ETA: 4s - loss: 8.2269 - binary_accuracy: 0.4896\\n22/32 [===================>..........] - ETA: 3s - loss: 8.2079 - binary_accuracy: 0.4908\\n23/32 [====================>.........] - ETA: 3s - loss: 8.2342 - binary_accuracy: 0.4891\\n24/32 [=====================>........] - ETA: 2s - loss: 8.2269 - binary_accuracy: 0.4896\\n25/32 [======================>.......] - ETA: 2s - loss: 8.1396 - binary_accuracy: 0.4950\\n26/32 [=======================>......] - ETA: 2s - loss: 8.0494 - binary_accuracy: 0.5006\\n27/32 [========================>.....] - ETA: 1s - loss: 8.0031 - binary_accuracy: 0.5035\\n28/32 [=========================>....] - ETA: 1s - loss: 8.0770 - binary_accuracy: 0.4989\\n29/32 [==========================>...] - ETA: 1s - loss: 7.9896 - binary_accuracy: 0.5043\\n30/32 [===========================>..] - ETA: 0s - loss: 7.9499 - binary_accuracy: 0.5068\\n31/32 [============================>.] - ETA: 0s - loss: 7.9534 - binary_accuracy: 0.5066\\n32/32 [==============================] - 12s 390ms/step - loss: 7.9725 - binary_accuracy: 0.5054 - val_loss: 8.0590 - val_binary_accuracy: 0.5000\\n\\nEpoch 00018: val_loss did not improve from 7.93313\\nEpoch 19/500\\n\\n 1/32 [..............................] - ETA: 11s - loss: 7.5554 - binary_accuracy: 0.5312\\n 2/32 [>.............................] - ETA: 11s - loss: 6.9257 - binary_accuracy: 0.5703\\n 3/32 [=>............................] - ETA: 10s - loss: 7.3035 - binary_accuracy: 0.5469\\n 4/32 [==>...........................] - ETA: 10s - loss: 7.3035 - binary_accuracy: 0.5469\\n 5/32 [===>..........................] - ETA: 9s - loss: 7.7568 - binary_accuracy: 0.5188 \\n 6/32 [====>.........................] - ETA: 9s - loss: 7.7233 - binary_accuracy: 0.5208\\n 7/32 [=====>........................] - ETA: 9s - loss: 7.6633 - binary_accuracy: 0.5246\\n 8/32 [======>.......................] - ETA: 8s - loss: 7.7442 - binary_accuracy: 0.5195\\n 9/32 [=======>......................] - ETA: 8s - loss: 7.9471 - binary_accuracy: 0.5069\\n10/32 [========>.....................] - ETA: 8s - loss: 7.8576 - binary_accuracy: 0.5125\\n11/32 [=========>....................] - ETA: 7s - loss: 8.0590 - binary_accuracy: 0.5000\\n12/32 [==========>...................] - ETA: 7s - loss: 8.0800 - binary_accuracy: 0.4987\\n13/32 [===========>..................] - ETA: 7s - loss: 8.0784 - binary_accuracy: 0.4988\\n14/32 [============>.................] - ETA: 6s - loss: 8.1310 - binary_accuracy: 0.4955\\n15/32 [=============>................] - ETA: 6s - loss: 8.0590 - binary_accuracy: 0.5000\\n16/32 [==============>...............] - ETA: 5s - loss: 8.0276 - binary_accuracy: 0.5020\\n17/32 [==============>...............] - ETA: 5s - loss: 7.9998 - binary_accuracy: 0.5037\\n18/32 [===============>..............] - ETA: 5s - loss: 8.0171 - binary_accuracy: 0.5026\\n19/32 [================>.............] - ETA: 4s - loss: 8.0193 - binary_accuracy: 0.5025\\n20/32 [=================>............] - ETA: 4s - loss: 7.9709 - binary_accuracy: 0.5055\\n21/32 [==================>...........] - ETA: 4s - loss: 7.9271 - binary_accuracy: 0.5082\\n22/32 [===================>..........] - ETA: 3s - loss: 7.9560 - binary_accuracy: 0.5064\\n23/32 [====================>.........] - ETA: 3s - loss: 7.9167 - binary_accuracy: 0.5088\\n24/32 [=====================>........] - ETA: 2s - loss: 7.9331 - binary_accuracy: 0.5078\\n25/32 [======================>.......] - ETA: 2s - loss: 7.8676 - binary_accuracy: 0.5119\\n26/32 [=======================>......] - ETA: 2s - loss: 7.8750 - binary_accuracy: 0.5114\\n27/32 [========================>.....] - ETA: 1s - loss: 7.8538 - binary_accuracy: 0.5127\\n28/32 [=========================>....] - ETA: 1s - loss: 7.8971 - binary_accuracy: 0.5100\\n29/32 [==========================>...] - ETA: 1s - loss: 7.8854 - binary_accuracy: 0.5108\\n30/32 [===========================>..] - ETA: 0s - loss: 7.9415 - binary_accuracy: 0.5073\\n31/32 [============================>.] - ETA: 0s - loss: 7.9859 - binary_accuracy: 0.5045\\n32/32 [==============================] - 12s 390ms/step - loss: 7.9961 - binary_accuracy: 0.5039 - val_loss: 8.0276 - val_binary_accuracy: 0.5020\\n\\nEpoch 00019: val_loss did not improve from 7.93313\\nEpoch 20/500\\n\\n 1/32 [..............................] - ETA: 11s - loss: 9.0664 - binary_accuracy: 0.4375\\n 2/32 [>.............................] - ETA: 11s - loss: 8.3109 - binary_accuracy: 0.4844\\n 3/32 [=>............................] - ETA: 10s - loss: 8.2269 - binary_accuracy: 0.4896\\n 4/32 [==>...........................] - ETA: 10s - loss: 8.5627 - binary_accuracy: 0.4688\\n 5/32 [===>..........................] - ETA: 9s - loss: 8.5124 - binary_accuracy: 0.4719 \\n 6/32 [====>.........................] - ETA: 9s - loss: 8.3948 - binary_accuracy: 0.4792\\n 7/32 [=====>........................] - ETA: 9s - loss: 8.2389 - binary_accuracy: 0.4888\\n 8/32 [======>.......................] - ETA: 8s - loss: 8.1850 - binary_accuracy: 0.4922\\n 9/32 [=======>......................] - ETA: 8s - loss: 8.1710 - binary_accuracy: 0.4931\\n10/32 [========>.....................] - ETA: 8s - loss: 8.1598 - binary_accuracy: 0.4938\\n11/32 [=========>....................] - ETA: 7s - loss: 8.1506 - binary_accuracy: 0.4943\\n12/32 [==========>...................] - ETA: 7s - loss: 8.1220 - binary_accuracy: 0.4961\\n13/32 [===========>..................] - ETA: 6s - loss: 8.0784 - binary_accuracy: 0.4988\\n14/32 [============>.................] - ETA: 6s - loss: 8.0590 - binary_accuracy: 0.5000\\n15/32 [=============>................] - ETA: 6s - loss: 7.9079 - binary_accuracy: 0.5094\\n16/32 [==============>...............] - ETA: 5s - loss: 7.9331 - binary_accuracy: 0.5078\\n17/32 [==============>...............] - ETA: 5s - loss: 7.9998 - binary_accuracy: 0.5037\\n18/32 [===============>..............] - ETA: 5s - loss: 8.0870 - binary_accuracy: 0.4983\\n19/32 [================>.............] - ETA: 4s - loss: 8.1121 - binary_accuracy: 0.4967\\n20/32 [=================>............] - ETA: 4s - loss: 8.0716 - binary_accuracy: 0.4992\\n21/32 [==================>...........] - ETA: 4s - loss: 8.0950 - binary_accuracy: 0.4978\\n22/32 [===================>..........] - ETA: 3s - loss: 8.1392 - binary_accuracy: 0.4950\\n23/32 [====================>.........] - ETA: 3s - loss: 8.1466 - binary_accuracy: 0.4946\\n24/32 [=====================>........] - ETA: 2s - loss: 8.1010 - binary_accuracy: 0.4974\\n25/32 [======================>.......] - ETA: 2s - loss: 8.0993 - binary_accuracy: 0.4975\\n26/32 [=======================>......] - ETA: 2s - loss: 8.1172 - binary_accuracy: 0.4964\\n27/32 [========================>.....] - ETA: 1s - loss: 8.0684 - binary_accuracy: 0.4994\\n28/32 [=========================>....] - ETA: 1s - loss: 8.1130 - binary_accuracy: 0.4967\\n29/32 [==========================>...] - ETA: 1s - loss: 8.1025 - binary_accuracy: 0.4973\\n30/32 [===========================>..] - ETA: 0s - loss: 8.0674 - binary_accuracy: 0.4995\\n31/32 [============================>.] - ETA: 0s - loss: 8.0509 - binary_accuracy: 0.5005\\n32/32 [==============================] - 12s 390ms/step - loss: 8.0197 - binary_accuracy: 0.5024 - val_loss: 7.9961 - val_binary_accuracy: 0.5039\\n\\nEpoch 00020: val_loss did not improve from 7.93313\\nEpoch 21/500\\n\\n 1/32 [..............................] - ETA: 11s - loss: 7.8072 - binary_accuracy: 0.5156\\n 2/32 [>.............................] - ETA: 11s - loss: 7.4294 - binary_accuracy: 0.5391\\n 3/32 [=>............................] - ETA: 10s - loss: 8.0590 - binary_accuracy: 0.5000\\n 4/32 [==>...........................] - ETA: 10s - loss: 8.3739 - binary_accuracy: 0.4805\\n 5/32 [===>..........................] - ETA: 9s - loss: 8.3109 - binary_accuracy: 0.4844 \\n 6/32 [====>.........................] - ETA: 9s - loss: 8.3948 - binary_accuracy: 0.4792\\n 7/32 [=====>........................] - ETA: 9s - loss: 8.2389 - binary_accuracy: 0.4888\\n 8/32 [======>.......................] - ETA: 8s - loss: 8.3109 - binary_accuracy: 0.4844\\n 9/32 [=======>......................] - ETA: 8s - loss: 8.3389 - binary_accuracy: 0.4826\\n10/32 [========>.....................] - ETA: 8s - loss: 8.4116 - binary_accuracy: 0.4781\\n11/32 [=========>....................] - ETA: 7s - loss: 8.4712 - binary_accuracy: 0.4744\\n12/32 [==========>...................] - ETA: 7s - loss: 8.4158 - binary_accuracy: 0.4779\\n13/32 [===========>..................] - ETA: 7s - loss: 8.4271 - binary_accuracy: 0.4772\\n14/32 [============>.................] - ETA: 6s - loss: 8.3109 - binary_accuracy: 0.4844\\n15/32 [=============>................] - ETA: 6s - loss: 8.2102 - binary_accuracy: 0.4906\\n16/32 [==============>...............] - ETA: 5s - loss: 8.2007 - binary_accuracy: 0.4912\\n17/32 [==============>...............] - ETA: 5s - loss: 8.2072 - binary_accuracy: 0.4908\\n18/32 [===============>..............] - ETA: 5s - loss: 8.2130 - binary_accuracy: 0.4905\\n19/32 [================>.............] - ETA: 4s - loss: 8.2844 - binary_accuracy: 0.4860\\n20/32 [=================>............] - ETA: 4s - loss: 8.2983 - binary_accuracy: 0.4852\\n21/32 [==================>...........] - ETA: 4s - loss: 8.2509 - binary_accuracy: 0.4881\\n22/32 [===================>..........] - ETA: 3s - loss: 8.2193 - binary_accuracy: 0.4901\\n23/32 [====================>.........] - ETA: 3s - loss: 8.2342 - binary_accuracy: 0.4891\\n24/32 [=====================>........] - ETA: 2s - loss: 8.1850 - binary_accuracy: 0.4922\\n25/32 [======================>.......] - ETA: 2s - loss: 8.1195 - binary_accuracy: 0.4963\\n26/32 [=======================>......] - ETA: 2s - loss: 8.1075 - binary_accuracy: 0.4970\\n27/32 [========================>.....] - ETA: 1s - loss: 8.1150 - binary_accuracy: 0.4965\\n28/32 [=========================>....] - ETA: 1s - loss: 8.1310 - binary_accuracy: 0.4955\\n29/32 [==========================>...] - ETA: 1s - loss: 8.1633 - binary_accuracy: 0.4935\\n30/32 [===========================>..] - ETA: 0s - loss: 8.0758 - binary_accuracy: 0.4990\\n31/32 [============================>.] - ETA: 0s - loss: 8.0266 - binary_accuracy: 0.5020\\n32/32 [==============================] - 12s 389ms/step - loss: 8.0118 - binary_accuracy: 0.5029 - val_loss: 8.1535 - val_binary_accuracy: 0.4941\\n\\nEpoch 00021: val_loss did not improve from 7.93313\\nEpoch 22/500\\n\\n 1/32 [..............................] - ETA: 11s - loss: 8.0590 - binary_accuracy: 0.5000\\n 2/32 [>.............................] - ETA: 11s - loss: 7.0517 - binary_accuracy: 0.5625\\n 3/32 [=>............................] - ETA: 10s - loss: 7.0517 - binary_accuracy: 0.5625\\n 4/32 [==>...........................] - ETA: 10s - loss: 7.2406 - binary_accuracy: 0.5508\\n 5/32 [===>..........................] - ETA: 9s - loss: 7.1020 - binary_accuracy: 0.5594 \\n 6/32 [====>.........................] - ETA: 9s - loss: 7.1776 - binary_accuracy: 0.5547\\n 7/32 [=====>........................] - ETA: 9s - loss: 7.3755 - binary_accuracy: 0.5424\\n 8/32 [======>.......................] - ETA: 8s - loss: 7.3350 - binary_accuracy: 0.5449\\n 9/32 [=======>......................] - ETA: 8s - loss: 7.3315 - binary_accuracy: 0.5451\\n10/32 [========>.....................] - ETA: 8s - loss: 7.4294 - binary_accuracy: 0.5391\\n11/32 [=========>....................] - ETA: 7s - loss: 7.6240 - binary_accuracy: 0.5270\\n12/32 [==========>...................] - ETA: 7s - loss: 7.5554 - binary_accuracy: 0.5312\\n13/32 [===========>..................] - ETA: 6s - loss: 7.6135 - binary_accuracy: 0.5276\\n14/32 [============>.................] - ETA: 6s - loss: 7.6633 - binary_accuracy: 0.5246\\n15/32 [=============>................] - ETA: 6s - loss: 7.6729 - binary_accuracy: 0.5240\\n16/32 [==============>...............] - ETA: 5s - loss: 7.7442 - binary_accuracy: 0.5195\\n17/32 [==============>...............] - ETA: 5s - loss: 7.7628 - binary_accuracy: 0.5184\\n18/32 [===============>..............] - ETA: 5s - loss: 7.8212 - binary_accuracy: 0.5148\\n19/32 [================>.............] - ETA: 4s - loss: 7.8205 - binary_accuracy: 0.5148\\n20/32 [=================>............] - ETA: 4s - loss: 7.7820 - binary_accuracy: 0.5172\\n21/32 [==================>...........] - ETA: 4s - loss: 7.8312 - binary_accuracy: 0.5141\\n22/32 [===================>..........] - ETA: 3s - loss: 7.8988 - binary_accuracy: 0.5099\\n23/32 [====================>.........] - ETA: 3s - loss: 7.9933 - binary_accuracy: 0.5041\\n24/32 [=====================>........] - ETA: 2s - loss: 7.9856 - binary_accuracy: 0.5046\\n25/32 [======================>.......] - ETA: 2s - loss: 7.9986 - binary_accuracy: 0.5038\\n26/32 [=======================>......] - ETA: 2s - loss: 8.0203 - binary_accuracy: 0.5024\\n27/32 [========================>.....] - ETA: 1s - loss: 8.0497 - binary_accuracy: 0.5006\\n28/32 [=========================>....] - ETA: 1s - loss: 8.0411 - binary_accuracy: 0.5011\\n29/32 [==========================>...] - ETA: 1s - loss: 8.0243 - binary_accuracy: 0.5022\\n30/32 [===========================>..] - ETA: 0s - loss: 8.0171 - binary_accuracy: 0.5026\\n31/32 [============================>.] - ETA: 0s - loss: 8.0103 - binary_accuracy: 0.5030\\n32/32 [==============================] - 12s 390ms/step - loss: 8.0197 - binary_accuracy: 0.5024 - val_loss: 7.9646 - val_binary_accuracy: 0.5059\\n\\nEpoch 00022: val_loss did not improve from 7.93313\\nEpoch 23/500\\n\\n 1/32 [..............................] - ETA: 11s - loss: 5.7924 - binary_accuracy: 0.6406\\n 2/32 [>.............................] - ETA: 11s - loss: 7.1776 - binary_accuracy: 0.5547\\n 3/32 [=>............................] - ETA: 10s - loss: 7.7233 - binary_accuracy: 0.5208\\n 4/32 [==>...........................] - ETA: 10s - loss: 7.9961 - binary_accuracy: 0.5039\\n 5/32 [===>..........................] - ETA: 9s - loss: 8.1598 - binary_accuracy: 0.4938 \\n 6/32 [====>.........................] - ETA: 9s - loss: 8.0171 - binary_accuracy: 0.5026\\n 7/32 [=====>........................] - ETA: 9s - loss: 8.1310 - binary_accuracy: 0.4955\\n 8/32 [======>.......................] - ETA: 8s - loss: 8.1535 - binary_accuracy: 0.4941\\n 9/32 [=======>......................] - ETA: 8s - loss: 8.3389 - binary_accuracy: 0.4826\\n10/32 [========>.....................] - ETA: 8s - loss: 8.2857 - binary_accuracy: 0.4859\\n11/32 [=========>....................] - ETA: 7s - loss: 8.3567 - binary_accuracy: 0.4815\\n12/32 [==========>...................] - ETA: 7s - loss: 8.3109 - binary_accuracy: 0.4844\\n13/32 [===========>..................] - ETA: 6s - loss: 8.2721 - binary_accuracy: 0.4868\\n14/32 [============>.................] - ETA: 6s - loss: 8.2030 - binary_accuracy: 0.4911\\n15/32 [=============>................] - ETA: 6s - loss: 8.1430 - binary_accuracy: 0.4948\\n16/32 [==============>...............] - ETA: 5s - loss: 8.1220 - binary_accuracy: 0.4961\\n17/32 [==============>...............] - ETA: 5s - loss: 8.0294 - binary_accuracy: 0.5018\\n18/32 [===============>..............] - ETA: 5s - loss: 8.0451 - binary_accuracy: 0.5009\\n19/32 [================>.............] - ETA: 4s - loss: 8.1253 - binary_accuracy: 0.4959\\n20/32 [=================>............] - ETA: 4s - loss: 8.1850 - binary_accuracy: 0.4922\\n21/32 [==================>...........] - ETA: 4s - loss: 8.0830 - binary_accuracy: 0.4985\\n22/32 [===================>..........] - ETA: 3s - loss: 8.0705 - binary_accuracy: 0.4993\\n23/32 [====================>.........] - ETA: 3s - loss: 8.1028 - binary_accuracy: 0.4973\\n24/32 [=====================>........] - ETA: 2s - loss: 8.0695 - binary_accuracy: 0.4993\\n25/32 [======================>.......] - ETA: 2s - loss: 8.0389 - binary_accuracy: 0.5012\\n26/32 [=======================>......] - ETA: 2s - loss: 8.0203 - binary_accuracy: 0.5024\\n27/32 [========================>.....] - ETA: 1s - loss: 8.0497 - binary_accuracy: 0.5006\\n28/32 [=========================>....] - ETA: 1s - loss: 8.0411 - binary_accuracy: 0.5011\\n29/32 [==========================>...] - ETA: 1s - loss: 8.0504 - binary_accuracy: 0.5005\\n30/32 [===========================>..] - ETA: 0s - loss: 8.0171 - binary_accuracy: 0.5026\\n31/32 [============================>.] - ETA: 0s - loss: 8.0509 - binary_accuracy: 0.5005\\n32/32 [==============================] - 12s 390ms/step - loss: 8.0276 - binary_accuracy: 0.5020 - val_loss: 7.9331 - val_binary_accuracy: 0.5078\\n\\nEpoch 00023: val_loss did not improve from 7.93313\\nEpoch 00023: early stopping\\nINFO - gender_predict_conv_gridsearch - Result: {\\'history\\': {\\'val_loss\\': [7.996086537837982, 8.027567207813263, 7.933125078678131, 8.059047639369965, 8.12200915813446, 8.090528547763824, 8.09052848815918, 8.05904769897461, 8.027567028999329, 7.996086478233337, 8.027567267417908, 8.05904769897461, 7.996086478233337, 8.122009098529816, 8.027567088603973, 8.027567088603973, 7.933125078678131, 8.059047818183899, 8.027567148208618, 7.996086597442627, 8.153489470481873, 7.964605808258057, 7.933125138282776], \\'val_binary_accuracy\\': [0.50390625, 0.501953125, 0.5078125, 0.5, 0.49609375, 0.498046875, 0.498046875, 0.5, 0.501953125, 0.50390625, 0.501953125, 0.5, 0.50390625, 0.49609375, 0.501953125, 0.501953125, 0.5078125, 0.5, 0.501953125, 0.50390625, 0.494140625, 0.505859375, 0.5078125], \\'loss\\': [7.9119028598070145, 8.011826828122139, 7.988216266036034, 8.011826857924461, 8.035437390208244, 8.01969689130783, 8.01969689130783, 7.980346158146858, 8.059047773480415, 8.043307363986969, 8.059047758579254, 8.043307393789291, 8.003956735134125, 7.996086418628693, 8.011826768517494, 8.011826768517494, 8.059047788381577, 7.972475960850716, 7.996086403727531, 8.019697085022926, 8.011826753616333, 8.01969689130783, 8.02756716310978], \\'binary_accuracy\\': [0.50146484375, 0.5029296875, 0.50439453125, 0.5029296875, 0.50146484375, 0.50244140625, 0.50244140625, 0.5048828125, 0.5, 0.5009765625, 0.5, 0.5009765625, 0.50341796875, 0.50390625, 0.5029296875, 0.5029296875, 0.5, 0.50537109375, 0.50390625, 0.50244140625, 0.5029296875, 0.50244140625, 0.501953125]}, \\'val_scores\\': {\\'min_val_loss\\': 7.933125078678131, \\'max_val_acc\\': 0.5078125}, \\'test_scores\\': {\\'f1\\': 0.8424242424242425, \\'acc\\': 0.7277486910994765, \\'auc\\': 0.5}}\\nINFO - gender_predict_conv_gridsearch - Completed after 0:07:20\\n',\n",
       " 'info': {},\n",
       " 'heartbeat': datetime.datetime(2019, 7, 16, 20, 43, 52, 805000),\n",
       " 'result': {'history': {'binary_accuracy': [0.50146484375,\n",
       "    0.5029296875,\n",
       "    0.50439453125,\n",
       "    0.5029296875,\n",
       "    0.50146484375,\n",
       "    0.50244140625,\n",
       "    0.50244140625,\n",
       "    0.5048828125,\n",
       "    0.5,\n",
       "    0.5009765625,\n",
       "    0.5,\n",
       "    0.5009765625,\n",
       "    0.50341796875,\n",
       "    0.50390625,\n",
       "    0.5029296875,\n",
       "    0.5029296875,\n",
       "    0.5,\n",
       "    0.50537109375,\n",
       "    0.50390625,\n",
       "    0.50244140625,\n",
       "    0.5029296875,\n",
       "    0.50244140625,\n",
       "    0.501953125],\n",
       "   'loss': [7.9119028598070145,\n",
       "    8.011826828122139,\n",
       "    7.988216266036034,\n",
       "    8.011826857924461,\n",
       "    8.035437390208244,\n",
       "    8.01969689130783,\n",
       "    8.01969689130783,\n",
       "    7.980346158146858,\n",
       "    8.059047773480415,\n",
       "    8.043307363986969,\n",
       "    8.059047758579254,\n",
       "    8.043307393789291,\n",
       "    8.003956735134125,\n",
       "    7.996086418628693,\n",
       "    8.011826768517494,\n",
       "    8.011826768517494,\n",
       "    8.059047788381577,\n",
       "    7.972475960850716,\n",
       "    7.996086403727531,\n",
       "    8.019697085022926,\n",
       "    8.011826753616333,\n",
       "    8.01969689130783,\n",
       "    8.02756716310978],\n",
       "   'val_binary_accuracy': [0.50390625,\n",
       "    0.501953125,\n",
       "    0.5078125,\n",
       "    0.5,\n",
       "    0.49609375,\n",
       "    0.498046875,\n",
       "    0.498046875,\n",
       "    0.5,\n",
       "    0.501953125,\n",
       "    0.50390625,\n",
       "    0.501953125,\n",
       "    0.5,\n",
       "    0.50390625,\n",
       "    0.49609375,\n",
       "    0.501953125,\n",
       "    0.501953125,\n",
       "    0.5078125,\n",
       "    0.5,\n",
       "    0.501953125,\n",
       "    0.50390625,\n",
       "    0.494140625,\n",
       "    0.505859375,\n",
       "    0.5078125],\n",
       "   'val_loss': [7.996086537837982,\n",
       "    8.027567207813263,\n",
       "    7.933125078678131,\n",
       "    8.059047639369965,\n",
       "    8.12200915813446,\n",
       "    8.090528547763824,\n",
       "    8.09052848815918,\n",
       "    8.05904769897461,\n",
       "    8.027567028999329,\n",
       "    7.996086478233337,\n",
       "    8.027567267417908,\n",
       "    8.05904769897461,\n",
       "    7.996086478233337,\n",
       "    8.122009098529816,\n",
       "    8.027567088603973,\n",
       "    8.027567088603973,\n",
       "    7.933125078678131,\n",
       "    8.059047818183899,\n",
       "    8.027567148208618,\n",
       "    7.996086597442627,\n",
       "    8.153489470481873,\n",
       "    7.964605808258057,\n",
       "    7.933125138282776]},\n",
       "  'test_scores': {'acc': 0.7277486910994765,\n",
       "   'auc': 0.5,\n",
       "   'f1': 0.8424242424242425},\n",
       "  'val_scores': {'max_val_acc': {'py/id': 51}, 'min_val_loss': {'py/id': 75}}},\n",
       " 'stop_time': datetime.datetime(2019, 7, 16, 20, 43, 52, 803000)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs.find(successful_run_params)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
