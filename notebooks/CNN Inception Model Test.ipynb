{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.realpath(\"..\"))\n",
    "os.environ[\"TF_XLA_FLAGS\"]=\"--tf_xla_cpu_global_jit\"\n",
    "\n",
    "import util_funcs\n",
    "from importlib import reload\n",
    "import data_reader as read\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import constants\n",
    "import clinical_text_analysis as cta\n",
    "import tsfresh\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, roc_curve\n",
    "from os import path\n",
    "import keras_models.dataGen as dg\n",
    "import predictGenderConvExp as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, LSTM, Dense, Activation, Conv2D, Concatenate, Dropout, MaxPool2D, Conv3D, Flatten, LeakyReLU, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing in the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = pkl.load(open(\"../standardized_combined_simple_ensemble_train_data.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = pkl.load(open(\"../standardized_combined_simple_ensemble_test_data.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "validData = pkl.load(open(\"../valid_standardized_combined_simple_ensemble_train_data.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_x_y(data):\n",
    "    x_data = np.stack([datum[0] for datum in data])\n",
    "    x_data = x_data.reshape((*x_data.shape, 1))\n",
    "    x_data.transpose(0, 2, 1, 3)\n",
    "    y_data = np.array([datum[1] for datum in data])\n",
    "    y_data = keras.utils.to_categorical(y_data)\n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataX, testDataY = generate_x_y(testData)\n",
    "del testData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a quick set of architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_models.vanPutten import inception_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = inception_like((500, 21, 1), num_filters=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import multi_gpu_model\n",
    "model = multi_gpu_model(model, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "adam = Adam(lr=0.002)\n",
    "model.compile(adam, loss=\"categorical_crossentropy\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 500, 21, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 500, 21, 1)   0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 500, 21, 1)   0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_5 (Model)                 (None, 2)            9394702     lambda_5[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Concatenate)           (None, 2)            0           model_5[1][0]                    \n",
      "                                                                 model_5[2][0]                    \n",
      "==================================================================================================\n",
      "Total params: 9,394,702\n",
      "Trainable params: 9,388,102\n",
      "Non-trainable params: 6,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "cb = [EarlyStopping(monitor=\"loss\", patience=3, verbose=True), EarlyStopping(monitor=\"val_loss\", patience=5, verbose=True), ModelCheckpoint(\"yolo.h5\",save_best_only=True, verbose=True),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb.append(ModelCheckpoint(\"yolo_bin_acc.h5\",save_best_only=True, verbose=True, monitor=\"val_acc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'keras_models.dataGen' from '/home/ms994/dbmi_eeg_clustering/keras_models/dataGen.py'>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataDg = dg.EdfDataGenerator(trainData, precache=True,\n",
    "        time_first=True,\n",
    "        n_classes=2, batch_size=64, max_length=500, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validDataDg = dg.EdfDataGenerator(validData, precache=True,\n",
    "        time_first=True,\n",
    "        n_classes=2, batch_size=32, max_length=500, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 500, 21, 1)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataDg[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1132/1132 [==============================] - 877s 775ms/step - loss: 5.5972 - acc: 0.6434 - val_loss: 7.1043 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 7.10428, saving model to yolo.h5\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.55556, saving model to yolo_bin_acc.h5\n",
      "Epoch 2/1000\n",
      "1132/1132 [==============================] - 855s 756ms/step - loss: 5.6786 - acc: 0.6454 - val_loss: 7.0592 - val_acc: 0.5590\n",
      "\n",
      "Epoch 00002: val_loss improved from 7.10428 to 7.05923, saving model to yolo.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.55556 to 0.55903, saving model to yolo_bin_acc.h5\n",
      "Epoch 3/1000\n",
      " 617/1132 [===============>..............] - ETA: 5:30 - loss: 5.4816 - acc: 0.6581"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(trainDataDg, callbacks=cb, validation_data=validDataDg, epochs=1000, use_multiprocessing=True, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"yolo_bin_acc.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(testDataX)\n",
    "roc_auc_score(testDataY.argmax(axis=1), y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(testDataY.argmax(axis=1), y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplingInfo = pkl.load(open(\"../test_standardized_edf_ensemble_sample_info.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_tokens = list(set([samplingInfo[key][\"token_file_path\"] for key in samplingInfo.keys()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembler = read.EdfDatasetEnsembler(\"combined\", \"01_tcp_ar\", generate_sample_info=False, edf_tokens=edf_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(edf_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembler.sampleInfo = samplingInfo\n",
    "ensembler.labels = testDataY.argmax(axis=1)\n",
    "ensembler.edf_tokens = edf_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from addict import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_vs_true = Dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trueLabel, pred = ensembler.getEnsemblePrediction(y_pred, mode=\"equal_vote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(trueLabel, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
