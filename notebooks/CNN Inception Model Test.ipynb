{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.realpath(\"..\"))\n",
    "os.environ[\"TF_XLA_FLAGS\"]=\"--tf_xla_cpu_global_jit\"\n",
    "\n",
    "import util_funcs\n",
    "from importlib import reload\n",
    "import data_reader as read\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import constants\n",
    "import clinical_text_analysis as cta\n",
    "import tsfresh\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, roc_curve\n",
    "from os import path\n",
    "import keras_models.dataGen as dg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, LSTM, Dense, Activation, Conv2D, Concatenate, Dropout, MaxPool2D, Conv3D, Flatten, LeakyReLU, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing in the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = pkl.load(open(\"/home/sawerchessread/standardized_combined_simple_ensemble_train_data.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = pkl.load(open(\"/home/sawerchessread/standardized_combined_simple_ensemble_test_data.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "validData = pkl.load(open(\"/home/sawerchessread/valid_standardized_combined_simple_ensemble_train_data.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_x_y(data):\n",
    "    x_data = np.stack([datum[0] for datum in data])\n",
    "    x_data = x_data.reshape((*x_data.shape, 1))\n",
    "    x_data.transpose(0, 2, 1, 3)\n",
    "    y_data = np.array([datum[1] for datum in data])\n",
    "    y_data = keras.utils.to_categorical(y_data)\n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataX, testDataY = generate_x_y(testData)\n",
    "del testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataX, trainDataY = generate_x_y(trainData)\n",
    "del trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "validDataX, validDataY = generate_x_y(validData)\n",
    "del validData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a quick set of architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0728 04:52:50.831261 140037694965568 deprecation_wrapper.py:119] From /src/miniconda3/envs/py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0728 04:52:51.160865 140037694965568 deprecation_wrapper.py:119] From /src/miniconda3/envs/py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0728 04:52:51.380967 140037694965568 deprecation_wrapper.py:119] From /src/miniconda3/envs/py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0728 04:52:51.506352 140037694965568 deprecation_wrapper.py:119] From /src/miniconda3/envs/py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0728 04:52:51.508681 140037694965568 deprecation_wrapper.py:119] From /src/miniconda3/envs/py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0728 04:52:51.514826 140037694965568 deprecation.py:506] From /src/miniconda3/envs/py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0728 04:52:51.535040 140037694965568 deprecation_wrapper.py:119] From /src/miniconda3/envs/py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0728 04:52:53.687807 140037694965568 deprecation_wrapper.py:119] From /src/miniconda3/envs/py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = Input(((500, 21, 1)))\n",
    "y1 = Conv2D(20, (3,3),  activation=\"relu\",)(x)\n",
    "y1 = MaxPool2D(pool_size=(2, 1),)(y1)\n",
    "y1 = Dropout(dropout)(y1)\n",
    "y1 = BatchNormalization()(y1)\n",
    "y1 = Conv2D(40, (3,3), activation=\"relu\",)(y1)\n",
    "y1 = MaxPool2D(pool_size=(2, 1),)(y1)\n",
    "y1 = Dropout(dropout)(y1)\n",
    "y1 = BatchNormalization()(y1)\n",
    "y1 = Conv2D(40, (3,3), activation=\"relu\",)(y1)\n",
    "y1 = MaxPool2D(pool_size=(2, 1),)(y1)\n",
    "y1 = Dropout(dropout)(y1)\n",
    "y1 = BatchNormalization()(y1)\n",
    "y1 = Conv2D(40, (3,3), activation=\"relu\",)(y1)\n",
    "y1 = MaxPool2D(pool_size=(2, 1),)(y1)\n",
    "y1 = Dropout(dropout)(y1)\n",
    "y1 = BatchNormalization()(y1)\n",
    "y1 = Conv2D(40, (3,3), activation=\"relu\",)(y1)\n",
    "y1 = MaxPool2D(pool_size=(2, 1),)(y1)\n",
    "y1 = Dropout(dropout)(y1)\n",
    "y1 = BatchNormalization()(y1)\n",
    "y1 = Conv2D(40, (3,3), activation=\"relu\",)(y1)\n",
    "y1 = MaxPool2D(pool_size=(2, 1),)(y1)\n",
    "y1 = Dropout(dropout)(y1)\n",
    "y1 = Flatten()(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = Conv2D(20, (2,2),  activation=\"relu\",)(x)\n",
    "y0 = MaxPool2D(pool_size=(2, 1),)(y0)\n",
    "y0 = Dropout(dropout)(y0)\n",
    "y0 = BatchNormalization()(y0)\n",
    "y0 = Conv2D(40, (2,2), activation=\"relu\",)(y0)\n",
    "y0 = MaxPool2D(pool_size=(2, 1),)(y0)\n",
    "y0 = Dropout(dropout)(y0)\n",
    "y0 = BatchNormalization()(y0)\n",
    "y0 = Conv2D(40, (2,2), activation=\"relu\",)(y0)\n",
    "y0 = MaxPool2D(pool_size=(2, 1),)(y0)\n",
    "y0 = Dropout(dropout)(y0)\n",
    "y0 = BatchNormalization()(y0)\n",
    "y0 = Conv2D(40, (2,2), activation=\"relu\",)(y0)\n",
    "y0 = MaxPool2D(pool_size=(2, 1),)(y0)\n",
    "y0 = Dropout(dropout)(y0)\n",
    "y0 = BatchNormalization()(y0)\n",
    "y0 = Conv2D(40, (2,2), activation=\"relu\",)(y0)\n",
    "y0 = MaxPool2D(pool_size=(2, 1),)(y0)\n",
    "y0 = Dropout(dropout)(y0)\n",
    "y0 = BatchNormalization()(y0)\n",
    "y0 = Conv2D(40, (2,2), activation=\"relu\",)(y0)\n",
    "y0 = MaxPool2D(pool_size=(2, 1),)(y0)\n",
    "y0 = Dropout(dropout)(y0)\n",
    "y0 = Flatten()(y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = Conv2D(20, (4,4),  activation=\"relu\",)(x)\n",
    "y2 = MaxPool2D(pool_size=(2, 1),)(y2)\n",
    "y2 = Dropout(dropout)(y2)\n",
    "y2 = BatchNormalization()(y2)\n",
    "y2 = Conv2D(40, (4,4), activation=\"relu\",)(y2)\n",
    "y2 = MaxPool2D(pool_size=(2, 1),)(y2)\n",
    "y2 = Dropout(dropout)(y2)\n",
    "y2 = BatchNormalization()(y2)\n",
    "y2 = Conv2D(40, (4,4), activation=\"relu\",)(y2)\n",
    "y2 = MaxPool2D(pool_size=(2, 1),)(y2)\n",
    "y2 = Dropout(dropout)(y2)\n",
    "y2 = BatchNormalization()(y2)\n",
    "y2 = Conv2D(40, (4,4), activation=\"relu\",)(y2)\n",
    "y2 = MaxPool2D(pool_size=(2, 1),)(y2)\n",
    "y2 = Dropout(dropout)(y2)\n",
    "y2 = BatchNormalization()(y2)\n",
    "y2 = Conv2D(40, (4,4), activation=\"relu\",)(y2)\n",
    "y2 = MaxPool2D(pool_size=(2, 1),)(y2)\n",
    "y2 = Dropout(dropout)(y2)\n",
    "y2 = BatchNormalization()(y2)\n",
    "y2 = Conv2D(40, (4,4), activation=\"relu\",)(y2)\n",
    "y2 = MaxPool2D(pool_size=(2, 1),)(y2)\n",
    "y2 = Dropout(dropout)(y2)\n",
    "y2 = Flatten()(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y3 = Conv2D(20, (5,5),  activation=\"relu\",)(x)\n",
    "y3 = MaxPool2D(pool_size=(2, 1),)(y3)\n",
    "y3 = Dropout(dropout)(y3)\n",
    "y3 = BatchNormalization()(y3)\n",
    "y3 = Conv2D(40, (5,5), activation=\"relu\",)(y3)\n",
    "y3 = MaxPool2D(pool_size=(2, 1),)(y3)\n",
    "y3 = Dropout(dropout)(y3)\n",
    "y3 = BatchNormalization()(y3)\n",
    "y3 = Conv2D(40, (5,5), activation=\"relu\",)(y3)\n",
    "y3 = MaxPool2D(pool_size=(2, 1),)(y3)\n",
    "y3 = Dropout(dropout)(y3)\n",
    "y3 = BatchNormalization()(y3)\n",
    "y3 = Conv2D(40, (5,5), activation=\"relu\",)(y3)\n",
    "y3 = MaxPool2D(pool_size=(2, 1),)(y3)\n",
    "y3 = Dropout(dropout)(y3)\n",
    "y3 = BatchNormalization()(y3)\n",
    "y3 = Conv2D(40, (5,5), activation=\"relu\",)(y3)\n",
    "y3 = MaxPool2D(pool_size=(2, 1),)(y3)\n",
    "y3 = Dropout(dropout)(y3)\n",
    "y3 = Flatten()(y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = Concatenate()([y0, y1, y2, y3])\n",
    "\n",
    "y = Dense(units=2, activation=\"softmax\")(y1)\n",
    "model = Model(inputs=x, outputs =y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0728 04:52:54.229012 140037694965568 deprecation_wrapper.py:119] From /src/miniconda3/envs/py37/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "adam = Adam(lr=0.00005)\n",
    "model.compile(adam, loss=\"categorical_crossentropy\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.training.Model"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "cb = [EarlyStopping(patience=10, verbose=True), ModelCheckpoint(\"yolo.h5\",save_best_only=True, verbose=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6089160000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "72490*500*21*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(trainDataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72490, 500, 21, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'keras_models.dataGen' from '/src/dbmi_eeg_clustering/keras_models/dataGen.py'>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = dg.EdfDataGenerator(trainData, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_models.dataGen.EdfDataGenerator at 0x7f5c92d47cc0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "validData = dg.EdfDataGenerator(validData, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"int\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-70fc8d540e75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/src/dbmi_eeg_clustering/keras_models/dataGen.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# Generate data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__data_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_IDs_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/dbmi_eeg_clustering/keras_models/dataGen.py\u001b[0m in \u001b[0;36m__data_generation\u001b[0;34m(self, list_IDs_temp)\u001b[0m\n\u001b[1;32m    174\u001b[0m         and allow for MultiProcessingDataset to work (only works for slices) '''\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_x_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_IDs_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthree_dim_pad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_first\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# we want batch by feature by time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/dbmi_eeg_clustering/keras_models/dataGen.py\u001b[0m in \u001b[0;36mget_x_y\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstance_order_first\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstance_order_first\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdatum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdatum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/dbmi_eeg_clustering/keras_models/dataGen.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;34m'Generate one batch of data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# Generate indexes of the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;31m# Find list of IDs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"int\") to list"
     ]
    }
   ],
   "source": [
    "trainData[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(trainData, epochs=1000, steps_per_epoch=32, callbacks=cb, validation_data=validData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"yolo.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(testDataX)\n",
    "roc_auc_score(testDataY.argmax(axis=1), y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(((500, 21, 1)))\n",
    "y1 = Conv2D(50, (3,3),  activation=\"relu\",)(x)\n",
    "y1 = MaxPool2D(pool_size=(2, 1),)(y1)\n",
    "y1 = Dropout(dropout)(y1)\n",
    "y1 = Conv2D(200, (3,3), activation=\"relu\",)(y1)\n",
    "y1 = MaxPool2D(pool_size=(2, 1),)(y1)\n",
    "y1 = Dropout(dropout)(y1)\n",
    "y1 = Flatten()(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = Conv2D(50, (2,2),  activation=\"relu\",)(x)\n",
    "y0 = MaxPool2D(pool_size=(2, 1),)(y0)\n",
    "y0 = Dropout(dropout)(y0)\n",
    "y0 = Conv2D(200, (2,2), activation=\"relu\",)(y0)\n",
    "y0 = MaxPool2D(pool_size=(2, 1),)(y0)\n",
    "y0 = Dropout(dropout)(y0)\n",
    "y0 = Conv2D(200, (2,2), activation=\"relu\",)(y0)\n",
    "y0 = MaxPool2D(pool_size=(2, 1),)(y0)\n",
    "y0 = Dropout(dropout)(y0)\n",
    "y0 = Flatten()(y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = Conv2D(50, (4,4),  activation=\"relu\",)(x)\n",
    "y2 = MaxPool2D(pool_size=(2, 1),)(y2)\n",
    "y2 = Dropout(dropout)(y2)\n",
    "y2 = Conv2D(200, (4,2), activation=\"relu\",)(y2)\n",
    "y2 = MaxPool2D(pool_size=(2, 1),)(y2)\n",
    "y2 = Dropout(dropout)(y2)\n",
    "y2 = Conv2D(200, (4,2), activation=\"relu\",)(y2)\n",
    "y2 = MaxPool2D(pool_size=(2, 1),)(y2)\n",
    "y2 = Dropout(dropout)(y2)\n",
    "y2 = Conv2D(200, (4,2), activation=\"relu\",)(y2)\n",
    "y2 = MaxPool2D(pool_size=(2, 1),)(y2)\n",
    "y2 = Dropout(dropout)(y2)\n",
    "y2 = Flatten()(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y3 = Conv2D(50, (5,5),  activation=\"relu\",)(x)\n",
    "y3 = MaxPool2D(pool_size=(2, 1),)(y3)\n",
    "y3 = Dropout(dropout)(y3)\n",
    "y3 = Conv2D(200, (5,5), activation=\"relu\",)(y3)\n",
    "y3 = MaxPool2D(pool_size=(2, 1),)(y3)\n",
    "y3 = Dropout(dropout)(y3)\n",
    "y3 = Flatten()(y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Concatenate()([y0, y1, y2, y3])\n",
    "y = Dense(units=2)(y)\n",
    "model2 = Model(inputs=x, outputs =y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "adam = Adam(lr=0.002)\n",
    "model2.compile(adam, loss=\"categorical_crossentropy\", metrics=[\"binary_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "cb = [EarlyStopping(patience=10), ModelCheckpoint(\"yolo.h5\",save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model2.fit(trainDataX, trainDataY, epochs=1000, callbacks=cb, validation_data=(validDataX, validDataY), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.models.load_model2(\"yolo.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model2.predict(testDataX)\n",
    "roc_auc_score(testDataY.argmax(axis=1), y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
